{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "# Agent with Long-Time Memory\n",
    "* We will build an Agent that will help us to **manage a ToDo list**.\n",
    "* It will decide:\n",
    "    * **when to save items** to our ToDo list.\n",
    "    * **to save either a user profile or a collection of ToDo items**.\n",
    "* In addition to semantic memory (user facts), it will also have **procedural memory**.\n",
    "    * Remember, the procedural memory is the system prompt. This will allow the user to set preferences for creating ToDo items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41c01d9-3a20-4d32-ba8b-89c7ae0d7f8f",
   "metadata": {},
   "source": [
    "## Recommended learning path\n",
    "This is a very good project to learn and practice all that you have learned until now.\n",
    "1. Watch the full video. Focus on understanding the main concepts.\n",
    "2. Repeat all the steps from scratch by yourself. Focus on understanding the details. Take your time.\n",
    "3. Think. Plan a list of interesting experiments to modify and improve the project.\n",
    "4. Experiment with one small feature at a time: clone the project and experiment only with that feature.\n",
    "5. And again, and again, and again. Until you master it. With the mentality and the motivation of an Olympic Athlete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f76a83-a98a-4186-83dc-d3aa1f429bb7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4065e336-d054-412c-8a3f-1fbec63e1bcd",
   "metadata": {},
   "source": [
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dda8d4-80cf-4b8f-9981-94edda5e9911",
   "metadata": {},
   "source": [
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 028-agent-with-LT-memory.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e766aa-f3e2-491f-be99-d0c6b700d47a",
   "metadata": {},
   "source": [
    "## Track operations\n",
    "From now on, we can track the operations **and the cost** of this project from LangSmith:\n",
    "* [smith.langchain.com](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f99504a-1b8f-4360-b342-0b81ffa06aff",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e5789-5bde-42e1-88dd-92dc8e363c24",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5514113-ddca-4ae9-9de6-0b9225b18f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef1e5c-b7e2-4a04-96c5-8f64377b8eba",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21d23f4-61f5-4227-8a75-7eefde6680ee",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df978ec5-bfd2-4167-bd33-86bc2687d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel35 = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chatModel4o = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2fd6a1-e350-454a-82d1-f9526ff4f3cc",
   "metadata": {},
   "source": [
    "## What is TrustCall doing in the background?\n",
    "* TrustCall allows us to have a deeper understanding of its operations. Here we will show you how to **discover what tool calls were made by TrustCall**.\n",
    "* We will **add a listener to the Trustcall extractor**. This will pass runs from the extractor's execution to a class, Spy, that we will define. The Spy class will extract **information about what tool calls were made by TrustCall**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a86d69a-5ad7-4fe2-a0b5-e99ac201b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414a242c-603b-4d9a-9b1f-ea61364bba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Inspect the tool calls made by Trustcall\n",
    "class Spy:\n",
    "    def __init__(self):\n",
    "        self.called_tools = []\n",
    "\n",
    "    def __call__(self, run):\n",
    "        # Collect information about the tool calls made by the extractor.\n",
    "        q = [run]\n",
    "        while q:\n",
    "            r = q.pop()\n",
    "            if r.child_runs:\n",
    "                q.extend(r.child_runs)\n",
    "            if r.run_type == \"chat_model\":\n",
    "                self.called_tools.append(\n",
    "                    r.outputs[\"generations\"][0][0][\"message\"][\"kwargs\"][\"tool_calls\"]\n",
    "                )\n",
    "\n",
    "# Initialize the spy\n",
    "spy = Spy()\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "# PAY ATTENTION HERE: see how we add the spy listener.\n",
    "# Add the spy as a listener\n",
    "trustcall_extractor_see_all_tool_calls = trustcall_extractor.with_listeners(on_end=spy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12854022-36ef-45d3-b22a-377e63afc401",
   "metadata": {},
   "source": [
    "## In case you are curious about how the Spy was developed...\n",
    "The **Spy** class tracks the tool calls made during the execution of a process (likely related to AI chat models or an extraction framework like LangChain).\n",
    "\n",
    "Let's break it down step by step:\n",
    "\n",
    "#### 1. The `Spy` class\n",
    "- The class is designed to **record tool calls** from an execution run.\n",
    "- It has an attribute `self.called_tools`, which is a list to store detected tool calls.\n",
    "\n",
    "#### 2. The `__call__` method\n",
    "- This makes the class callable like a function.\n",
    "- It takes an object `run` (probably representing a process or task execution).\n",
    "- It uses a queue (`q`) to **traverse through all child runs** (nested executions).\n",
    "\n",
    "#### 3. Processing runs\n",
    "- The loop extracts **child runs** recursively, meaning it goes through all levels of execution.\n",
    "- If the execution (`r`) is of type `\"chat_model\"`, it extracts tool call information from `r.outputs`.\n",
    "\n",
    "#### 4. Extracting tool calls\n",
    "- The tool calls are accessed via:\n",
    "  ```python\n",
    "  r.outputs[\"generations\"][0][0][\"message\"][\"kwargs\"][\"tool_calls\"]\n",
    "  ```\n",
    "  - `generations[0][0]`: Likely refers to the first generated response.\n",
    "  - `\"message\"` → `\"kwargs\"` → `\"tool_calls\"`: This navigates through a structured data format (probably JSON-like) to retrieve the tool call information.\n",
    "- This extracted tool call info is appended to `self.called_tools`.\n",
    "\n",
    "#### 5. Initializing the spy\n",
    "```python\n",
    "spy = Spy()\n",
    "```\n",
    "- This creates an instance of the `Spy` class, ready to inspect tool calls.\n",
    "\n",
    "#### Summary (Simple Explanation)\n",
    "- The **Spy** class keeps track of tools used during a process.\n",
    "- It goes through the execution history, including nested calls.\n",
    "- If the process involves a **chat model**, it extracts tool call details.\n",
    "- The extracted tool call information is stored in `self.called_tools` for later inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d88d289-a48d-41a6-8036-e24045d3516f",
   "metadata": {},
   "source": [
    "## OK. Let's first use Trustcall without the listener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc0919ff-c87a-4f61-85f6-7cd439f220e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instruction\n",
    "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
    "\n",
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Julio.\"), \n",
    "                AIMessage(content=\"Nice to meet you, Julio.\"), \n",
    "                HumanMessage(content=\"Yesterday I visited Sausalito.\")]\n",
    "\n",
    "# PAY ATTENTION HERE: we use the regular extractor.\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0af2a4f-e71e-4f2b-9a08-a04de8790a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_FrmbmeMKdSV8uQqdCQncKQW3)\n",
      " Call ID: call_FrmbmeMKdSV8uQqdCQncKQW3\n",
      "  Args:\n",
      "    content: Julio visited Sausalito yesterday.\n"
     ]
    }
   ],
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71f5e37e-0856-4a58-9fde-250d27f17759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Julio visited Sausalito yesterday.'\n"
     ]
    }
   ],
   "source": [
    "# Responses contain the memories that adhere to the schema\n",
    "for m in result[\"responses\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2cd2c32-5c7b-470b-b581-d89501607e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_FrmbmeMKdSV8uQqdCQncKQW3'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3038467b-a5d2-4438-a5df-0ea84ad0ffaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 'Memory', {'content': 'Julio visited Sausalito yesterday.'})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [AIMessage(content=\"That's great, what did you do after?\"), \n",
    "                        HumanMessage(content=\"I went to Tiburon and prepared a paella in the park.\"),                        \n",
    "                        AIMessage(content=\"What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I was thinking about finally learn to cook paella for the sake of my girlfriend.\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\"\n",
    "\n",
    "# We'll save existing memories, giving them an ID, key (tool name), and value\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8693d425-aaaa-4a77-80ce-c06e362f72a4",
   "metadata": {},
   "source": [
    "## And now let's see Trustcall with the listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7891c5e-17cb-4ae7-9886-43f1d52a081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAY ATTENTION HERE: See how we use the extractor with the listener.\n",
    "# Invoke the extractor with our updated conversation and existing memories\n",
    "result = trustcall_extractor_see_all_tool_calls.invoke({\"messages\": updated_conversation, \n",
    "                                                        \"existing\": existing_memories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7a59be0-7b94-4391-ab92-7647d7cb246b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_5pJ8BF9bsiFnFRUpXtbbqA2D', 'json_doc_id': '0'}\n",
      "{'id': 'call_Q3BjEuPA8PDzjLo70w0lL8rC'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "691b5555-b69a-4409-96db-41deef2b2b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_5pJ8BF9bsiFnFRUpXtbbqA2D)\n",
      " Call ID: call_5pJ8BF9bsiFnFRUpXtbbqA2D\n",
      "  Args:\n",
      "    content:  I went to Tiburon and prepared a paella in the park.\n",
      "  Memory (call_Q3BjEuPA8PDzjLo70w0lL8rC)\n",
      " Call ID: call_Q3BjEuPA8PDzjLo70w0lL8rC\n",
      "  Args:\n",
      "    content: I was thinking about finally learning to cook paella for the sake of my girlfriend.\n"
     ]
    }
   ],
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c2a1d6f-8d0f-4720-a41c-1627ffa68fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=' I went to Tiburon and prepared a paella in the park.'\n",
      "content='I was thinking about finally learning to cook paella for the sake of my girlfriend.'\n"
     ]
    }
   ],
   "source": [
    "# Parsed responses\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd008686-c03f-407d-9173-12fdf53ac44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'name': 'PatchDoc',\n",
       "   'args': {'json_doc_id': '0',\n",
       "    'planned_edits': 'Add the new memory content about visiting Tiburon and preparing paella in the park to the existing Memory instance.',\n",
       "    'patches': [{'op': 'add',\n",
       "      'path': '/content',\n",
       "      'value': ' I went to Tiburon and prepared a paella in the park.'}]},\n",
       "   'id': 'call_5pJ8BF9bsiFnFRUpXtbbqA2D',\n",
       "   'type': 'tool_call'},\n",
       "  {'name': 'Memory',\n",
       "   'args': {'content': 'I was thinking about finally learning to cook paella for the sake of my girlfriend.'},\n",
       "   'id': 'call_Q3BjEuPA8PDzjLo70w0lL8rC',\n",
       "   'type': 'tool_call'}]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the tool calls made by Trustcall\n",
    "spy.called_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca28151a-4c15-4b84-96a5-8c076286a017",
   "metadata": {},
   "source": [
    "## Let's review what we just did\n",
    "\n",
    "The previous code demonstrates how to **track tool calls** made by the **TrustCall extractor** in a conversation-processing workflow using LangGraph. Here's a simplified explanation of what each part does:\n",
    "\n",
    "\n",
    "#### Define Memory Schemas\n",
    "- **`Memory`** and **`MemoryCollection`** define the structure for storing extracted information.  \n",
    "- Example: Memories might include facts about the user, such as *\"User visited Sausalito yesterday.\"*\n",
    "\n",
    "\n",
    "#### Create a Spy Class\n",
    "- **`Spy`** keeps track of which tools TrustCall uses during processing.  \n",
    "- It inspects and logs tool calls embedded in the **`run`** structure, capturing details about interactions.\n",
    "\n",
    "\n",
    "#### Set Up the LLM and Extractor\n",
    "- **Model (`ChatOpenAI`)** simulates conversation processing.  \n",
    "- **TrustCall Extractor** is configured to:\n",
    "  - Use the **`Memory`** tool.  \n",
    "  - Automatically insert memories extracted from conversations.  \n",
    "\n",
    "The extractor processes user messages and identifies relevant information to store as memories.\n",
    "\n",
    "\n",
    "#### Attach Spy to the Extractor\n",
    "- The extractor is modified (`with_listeners`) to use the **Spy** object.  \n",
    "- **Spy** listens for tool calls at the end of the extraction process.\n",
    "\n",
    "\n",
    "#### Process Conversations \n",
    "- Conversations are passed into the extractor with an **instruction** to extract memories.  \n",
    "- The extractor outputs:\n",
    "  1. **Messages** – The processed conversation. \n",
    "  2. **Responses** – The extracted memories.  \n",
    "  3. **Metadata** – Information about the tool calls used.  \n",
    "\n",
    "\n",
    "#### Update Conversations and Memories \n",
    "- A new conversation is added with updated instructions.  \n",
    "- **Existing memories** are provided to allow updates and additions.  \n",
    "- The extractor processes the updates and outputs new data.\n",
    "\n",
    "\n",
    "#### Inspect Tool Calls \n",
    "- The **Spy** collects and logs all tool calls used during the process.  \n",
    "- It allows developers to see which tools were invoked and analyze how the extractor interacted with them.\n",
    "\n",
    "\n",
    "#### Purpose of the Code \n",
    "This code is primarily for **debugging and monitoring** the behavior of the TrustCall extractor. It helps developers understand how TrustCall uses tools to process and extract information during conversations, ensuring transparency and enabling improvements to the processing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af37c4b-5efb-429a-b864-136a8d27a311",
   "metadata": {},
   "source": [
    "## OK. That was good to know. Now let's start building our ToDo Agent.\n",
    "Our Agent will be able to decide when to update 3 elements in the long-term memory:\n",
    "* User profile data.\n",
    "* ToDo items.\n",
    "* System prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f647bb03-0a8c-4159-a09f-77ad2c8152dd",
   "metadata": {},
   "source": [
    "## We will create the UpdateMemory class to select the element in the long-term memory we will update at one particular moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0527515-7a7a-4b25-abfa-4416aa0f0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "\n",
    "# Update memory tool\n",
    "class UpdateMemory(TypedDict):\n",
    "    \"\"\" Decision on what memory type to update \"\"\"\n",
    "    update_type: Literal['user', 'todo', 'instructions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ebba14-2bde-4133-83f3-b0d6a2da04a5",
   "metadata": {},
   "source": [
    "## Let's review the previous code\n",
    "\n",
    "#### TypedDict \n",
    "- It is used to create a dictionary-like structure where each key has a specific name and type.   \n",
    "\n",
    "#### UpdateMemory  \n",
    "- A **class** that acts like a dictionary to represent a **decision on what memory type to update**.  \n",
    "- It has one key: **`update_type`**, which specifies what kind of memory needs to be updated.\n",
    "\n",
    "#### Literal  \n",
    "- Limits the value of **`update_type`** to one of **three predefined options**:\n",
    "     - `'user'` – Updates user-related memories.  \n",
    "     - `'todo'` – Updates task-related or to-do list memories.  \n",
    "     - `'instructions'` – Updates instructions or guidelines stored in memory.  \n",
    "\n",
    "\n",
    "#### Example Usage\n",
    "```python\n",
    "update = UpdateMemory(update_type='user')  # Valid\n",
    "update = UpdateMemory(update_type='todo')  # Valid\n",
    "update = UpdateMemory(update_type='notes') # Error! 'notes' is not allowed.\n",
    "```\n",
    "\n",
    "#### Purpose\n",
    "This code helps **categorize memory updates** into specific types, making the system more organized and reducing errors during updates. It ensures only valid memory types are passed, improving reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d063e-7798-4583-bd22-12aff673cf4e",
   "metadata": {},
   "source": [
    "## With that ready, let's now focus on building the agent\n",
    "* We will use the router route_message to make a binary decision to save memories.\n",
    "* The memory collection updating will be handled by Trustcall in the write_memory node, like we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2275312c-bda8-4047-baa2-1a2041f711b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from datetime import datetime\n",
    "from trustcall import create_extractor\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import merge_message_runs, HumanMessage, SystemMessage\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, END, START\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# User profile schema\n",
    "class Profile(BaseModel):\n",
    "    \"\"\"This is the profile of the user you are chatting with\"\"\"\n",
    "    name: Optional[str] = Field(description=\"The user's name\", default=None)\n",
    "    location: Optional[str] = Field(description=\"The user's location\", default=None)\n",
    "    job: Optional[str] = Field(description=\"The user's job\", default=None)\n",
    "    connections: list[str] = Field(\n",
    "        description=\"Personal connection of the user, such as family members, friends, or coworkers\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    interests: list[str] = Field(\n",
    "        description=\"Interests that the user has\", \n",
    "        default_factory=list\n",
    "    )\n",
    "\n",
    "# ToDo schema\n",
    "class ToDo(BaseModel):\n",
    "    task: str = Field(description=\"The task to be completed.\")\n",
    "    time_to_complete: Optional[int] = Field(description=\"Estimated time to complete the task (minutes).\")\n",
    "    deadline: Optional[datetime] = Field(\n",
    "        description=\"When the task needs to be completed by (if applicable)\",\n",
    "        default=None\n",
    "    )\n",
    "    solutions: list[str] = Field(\n",
    "        description=\"List of specific, actionable solutions (e.g., specific ideas, service providers, or concrete options relevant to completing the task)\",\n",
    "        min_items=1,\n",
    "        default_factory=list\n",
    "    )\n",
    "    status: Literal[\"not started\", \"in progress\", \"done\", \"archived\"] = Field(\n",
    "        description=\"Current status of the task\",\n",
    "        default=\"not started\"\n",
    "    )\n",
    "\n",
    "# Create the Trustcall extractor for updating the user profile \n",
    "profile_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Profile],\n",
    "    tool_choice=\"Profile\",\n",
    ")\n",
    "\n",
    "# Chatbot instruction for choosing what to update and what tools to call \n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful chatbot. \n",
    "\n",
    "You are designed to be a companion to a user, helping them keep track of their ToDo list.\n",
    "\n",
    "You have a long term memory which keeps track of three things:\n",
    "1. The user's profile (general information about them) \n",
    "2. The user's ToDo list\n",
    "3. General instructions for updating the ToDo list\n",
    "\n",
    "Here is the current User Profile (may be empty if no information has been collected yet):\n",
    "<user_profile>\n",
    "{user_profile}\n",
    "</user_profile>\n",
    "\n",
    "Here is the current ToDo List (may be empty if no tasks have been added yet):\n",
    "<todo>\n",
    "{todo}\n",
    "</todo>\n",
    "\n",
    "Here are the current user-specified preferences for updating the ToDo list (may be empty if no preferences have been specified yet):\n",
    "<instructions>\n",
    "{instructions}\n",
    "</instructions>\n",
    "\n",
    "Here are your instructions for reasoning about the user's messages:\n",
    "\n",
    "1. Reason carefully about the user's messages as presented below. \n",
    "\n",
    "2. Decide whether any of the your long-term memory should be updated:\n",
    "- If personal information was provided about the user, update the user's profile by calling UpdateMemory tool with type `user`\n",
    "- If tasks are mentioned, update the ToDo list by calling UpdateMemory tool with type `todo`\n",
    "- If the user has specified preferences for how to update the ToDo list, update the instructions by calling UpdateMemory tool with type `instructions`\n",
    "\n",
    "3. Tell the user that you have updated your memory, if appropriate:\n",
    "- Do not tell the user you have updated the user's profile\n",
    "- Tell the user them when you update the todo list\n",
    "- Do not tell the user that you have updated instructions\n",
    "\n",
    "4. Err on the side of updating the todo list. No need to ask for explicit permission.\n",
    "\n",
    "5. Respond naturally to user user after a tool call was made to save memories, or if no tool call was made.\"\"\"\n",
    "\n",
    "# Trustcall instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Reflect on following interaction. \n",
    "\n",
    "Use the provided tools to retain any necessary memories about the user. \n",
    "\n",
    "Use parallel tool calling to handle updates and insertions simultaneously.\n",
    "\n",
    "System Time: {time}\"\"\"\n",
    "\n",
    "# Instructions for updating the ToDo list\n",
    "CREATE_INSTRUCTIONS = \"\"\"Reflect on the following interaction.\n",
    "\n",
    "Based on this interaction, update your instructions for how to update ToDo list items. \n",
    "\n",
    "Use any feedback from the user to update how they like to have items added, etc.\n",
    "\n",
    "Your current instructions are:\n",
    "\n",
    "<current_instructions>\n",
    "{current_instructions}\n",
    "</current_instructions>\"\"\"\n",
    "\n",
    "# Node definitions\n",
    "def task_mAIstro(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memories from the store and use them to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve profile memory from the store\n",
    "    namespace = (\"profile\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    if memories:\n",
    "        user_profile = memories[0].value\n",
    "    else:\n",
    "        user_profile = None\n",
    "\n",
    "    # Retrieve task memory from the store\n",
    "    namespace = (\"todo\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    todo = \"\\n\".join(f\"{mem.value}\" for mem in memories)\n",
    "\n",
    "    # Retrieve custom instructions\n",
    "    namespace = (\"instructions\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    if memories:\n",
    "        instructions = memories[0].value\n",
    "    else:\n",
    "        instructions = \"\"\n",
    "    \n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, todo=todo, instructions=instructions)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.bind_tools([UpdateMemory], parallel_tool_calls=False).invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def update_profile(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"profile\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"Profile\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat())\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = profile_extractor.invoke({\"messages\": updated_messages, \n",
    "                                         \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated profile\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "\n",
    "# PAY ATTENTION HERE: We needed to define this function, that is used in the next one.\n",
    "# Did the LangGraph team miss this or are we missing something???\n",
    "def extract_tool_info(tool_calls, tool_name):\n",
    "    \"\"\"Extracts and summarizes information about tool calls.\"\"\"\n",
    "    updates = []\n",
    "    for tool_call in tool_calls:\n",
    "        if tool_call:\n",
    "            for call in tool_call:\n",
    "                if call['name'] == tool_name:\n",
    "                    # Collect the arguments or details about the tool call\n",
    "                    updates.append(f\"Updated {tool_name}: {call['args']}\")\n",
    "    return \"\\n\".join(updates) if updates else f\"No updates for {tool_name}.\"\n",
    "\n",
    "\n",
    "def update_todos(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"todo\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"ToDo\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat())\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # Initialize the spy for visibility into the tool calls made by Trustcall\n",
    "    spy = Spy()\n",
    "    \n",
    "    # Create the Trustcall extractor for updating the ToDo list \n",
    "    todo_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[ToDo],\n",
    "    tool_choice=tool_name,\n",
    "    enable_inserts=True\n",
    "    ).with_listeners(on_end=spy)\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = todo_extractor.invoke({\"messages\": updated_messages, \n",
    "                                    \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "        \n",
    "    # Respond to the tool call made in task_mAIstro, confirming the update\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "\n",
    "    # PAY ATTENTION: here is where the function extract_tool_info is being used.\n",
    "    # We needed to define it in order to prevent an error. See the previous function definition.\n",
    "    # Extract the changes made by Trustcall and add the the ToolMessage returned to task_mAIstro\n",
    "    todo_update_msg = extract_tool_info(spy.called_tools, tool_name)\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": todo_update_msg, \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "def update_instructions(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    \n",
    "    namespace = (\"instructions\", user_id)\n",
    "\n",
    "    existing_memory = store.get(namespace, \"user_instructions\")\n",
    "        \n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = CREATE_INSTRUCTIONS.format(current_instructions=existing_memory.value if existing_memory else None)\n",
    "    new_memory = model.invoke([SystemMessage(content=system_msg)]+state['messages'][:-1] + [HumanMessage(content=\"Please update the instructions based on the conversation\")])\n",
    "\n",
    "    # Overwrite the existing memory in the store \n",
    "    key = \"user_instructions\"\n",
    "    store.put(namespace, key, {\"memory\": new_memory.content})\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated instructions\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "# Conditional edge\n",
    "def route_message(state: MessagesState, config: RunnableConfig, store: BaseStore) -> Literal[END, \"update_todos\", \"update_instructions\", \"update_profile\"]:\n",
    "\n",
    "    \"\"\"Reflect on the memories and chat history to decide whether to update the memory collection.\"\"\"\n",
    "    message = state['messages'][-1]\n",
    "    if len(message.tool_calls) ==0:\n",
    "        return END\n",
    "    else:\n",
    "        tool_call = message.tool_calls[0]\n",
    "        if tool_call['args']['update_type'] == \"user\":\n",
    "            return \"update_profile\"\n",
    "        elif tool_call['args']['update_type'] == \"todo\":\n",
    "            return \"update_todos\"\n",
    "        elif tool_call['args']['update_type'] == \"instructions\":\n",
    "            return \"update_instructions\"\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "# Create the graph + all nodes\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define the flow of the memory extraction process\n",
    "builder.add_node(task_mAIstro)\n",
    "builder.add_node(update_todos)\n",
    "builder.add_node(update_profile)\n",
    "builder.add_node(update_instructions)\n",
    "builder.add_edge(START, \"task_mAIstro\")\n",
    "builder.add_conditional_edges(\"task_mAIstro\", route_message)\n",
    "builder.add_edge(\"update_todos\", \"task_mAIstro\")\n",
    "builder.add_edge(\"update_profile\", \"task_mAIstro\")\n",
    "builder.add_edge(\"update_instructions\", \"task_mAIstro\")\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# We compile the graph with the checkpointer and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f6bd3-0cc8-4e44-af34-6b22835903a9",
   "metadata": {},
   "source": [
    "## That is a very long code. Let's break it down.\n",
    "\n",
    "The previous code sets up a **conversation-based chatbot system** using LangGraph and TrustCall to manage and update **long-term memory** (user profile, ToDo list, and instructions) based on user inputs. Here's a **simplified explanation** of what each part does:\n",
    "\n",
    "\n",
    "#### Define Schemas for Memory\n",
    "- **Profile Schema:**  \n",
    "  Stores personal details about the user, such as name, location, job, connections, and interests.  \n",
    "- **ToDo Schema:**  \n",
    "  Manages tasks with details like deadlines, status, and solutions.  \n",
    "\n",
    "\n",
    "#### TrustCall Extractors\n",
    "- **Profile Extractor:**  \n",
    "  Updates user profiles based on conversations.  \n",
    "- **ToDo Extractor:**  \n",
    "  Updates tasks in the ToDo list based on chat inputs.  \n",
    "- **Instruction Updater:**  \n",
    "  Updates chatbot instructions for handling tasks based on user preferences.  \n",
    "\n",
    "Each extractor works with tools that are specifically designed to process the schemas and store relevant information.\n",
    "\n",
    "\n",
    "#### Instructions for the Chatbot\n",
    "- **MODEL_SYSTEM_MESSAGE:**  \n",
    "  Guides the chatbot to:\n",
    "  1. Update the profile if the user shares personal info.  \n",
    "  2. Update ToDo lists if tasks are mentioned.  \n",
    "  3. Update instructions based on user preferences.  \n",
    "- **TRUSTCALL_INSTRUCTION:**  \n",
    "  Ensures extracted data is reflected as memories using TrustCall tools.  \n",
    "\n",
    "\n",
    "#### Define Nodes (Functions) for Memory Updates\n",
    "- **`task_mAIstro`:**  \n",
    "  Loads existing memories (profile, tasks, and instructions) and responds based on user input, deciding which updates are needed.  \n",
    "- **`update_profile`:**  \n",
    "  Updates the user profile if personal information is detected in messages.  \n",
    "- **`update_todos`:**  \n",
    "  Updates the ToDo list with new tasks or changes based on user input.  \n",
    "- **`update_instructions`:**  \n",
    "  Updates chatbot preferences based on how the user wants the ToDo list handled.  \n",
    "\n",
    "Each function:\n",
    "1. Loads existing memory from storage.  \n",
    "2. Processes the chat messages.  \n",
    "3. Saves updated memory back into the store.  \n",
    "4. Confirms updates to the user if required.\n",
    "\n",
    "\n",
    "#### Decision Routing\n",
    "- **`route_message`:**  \n",
    "  Decides which node to process based on the latest tool call:  \n",
    "  - Update profile → `update_profile`.  \n",
    "  - Update tasks → `update_todos`.  \n",
    "  - Update instructions → `update_instructions`.  \n",
    "  - End processing if no update is required.\n",
    "\n",
    "\n",
    "#### Build the Conversation Flow\n",
    "- **StateGraph:**  \n",
    "  Defines the flow of conversation:  \n",
    "  1. Starts at **`task_mAIstro`** to process inputs.  \n",
    "  2. Routes updates to profile, tasks, or instructions as needed.  \n",
    "  3. Loops back to the start for continued processing.  \n",
    "\n",
    "- **Memory Management:**  \n",
    "  - **`InMemoryStore`:** Stores long-term memory across multiple interactions.  \n",
    "  - **`MemorySaver`:** Tracks short-term memory for the current conversation.  \n",
    "\n",
    "\n",
    "#### Visualize the Graph\n",
    "- Generates a **flowchart diagram** showing the process flow using Mermaid.js to visualize connections between nodes.  \n",
    "\n",
    "\n",
    "#### Example Workflow\n",
    "**Input:**  \n",
    "*User: \"I need to finish a report by Friday.\"*  \n",
    "\n",
    "**Process:**  \n",
    "1. Detects a task and updates the ToDo list.  \n",
    "2. Stores \"Finish report\" with a deadline of Friday.  \n",
    "3. Confirms the task addition to the user.  \n",
    "\n",
    "**Output:**  \n",
    "*Bot: \"I've added 'Finish report' to your ToDo list with a deadline on Friday.\"*  \n",
    "\n",
    "This setup enables dynamic, **memory-driven interactions**, making the chatbot smarter and more context-aware over time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6b4ad2-4003-48b3-948b-a4033bfb0778",
   "metadata": {},
   "source": [
    "## That was a good overview. Now let's dive into the most relevant parts of this code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111ce734-7c8d-4e87-9dfa-1182e4acedde",
   "metadata": {},
   "source": [
    "## Let's review the segment that defines the schemas for Profile and ToDo memories\n",
    "\n",
    "This segment of code defines **data structures** for storing information about the user and their tasks using Python's **Pydantic library**. It ensures data is organized and validated based on predefined formats.  \n",
    "\n",
    "#### User Profile Schema (`Profile`)\n",
    "\n",
    "This class represents **personal information** about the user.  \n",
    "\n",
    "- **`name`:** Stores the user's name (optional).  \n",
    "- **`location`:** Stores where the user is located (optional).  \n",
    "- **`job`:** Stores the user's job or profession (optional).  \n",
    "- **`connections`:** A list of people connected to the user (e.g., family, friends, coworkers).  \n",
    "  - Default is an **empty list**.  \n",
    "- **`interests`:** A list of the user's hobbies or interests.  \n",
    "  - Default is an **empty list**.  \n",
    "\n",
    "**Purpose:**  \n",
    "Keeps track of personal details about the user to **personalize responses** and adapt interactions based on their profile.\n",
    "\n",
    "\n",
    "#### ToDo Schema (`ToDo`)\n",
    "\n",
    "This class defines the structure for storing and managing **tasks**.  \n",
    "\n",
    "- **`task`:** A description of the task to be completed (required).  \n",
    "- **`time_to_complete`:** Estimated time to complete the task, in minutes (optional).  \n",
    "- **`deadline`:** A specific **date and time** by which the task should be completed (optional).  \n",
    "- **`solutions`:** A list of **actionable steps or ideas** to complete the task.  \n",
    "  - Must contain at least **one solution** and defaults to an **empty list**.  \n",
    "- **`status`:** Tracks the **progress** of the task.  \n",
    "  - Can be one of these values:  \n",
    "    - `\"not started\"` (default)  \n",
    "    - `\"in progress\"`  \n",
    "    - `\"done\"`  \n",
    "    - `\"archived\"`  \n",
    "\n",
    "**Purpose:**  \n",
    "Manages the **ToDo list** by storing tasks, deadlines, and progress to help the chatbot track and update activities effectively.\n",
    "\n",
    "\n",
    "#### Example Data\n",
    "\n",
    "**User Profile:**\n",
    "```python\n",
    "profile = Profile(\n",
    "    name=\"Alice\",\n",
    "    location=\"San Francisco\",\n",
    "    job=\"Engineer\",\n",
    "    connections=[\"Bob\", \"Carol\"],\n",
    "    interests=[\"hiking\", \"photography\"]\n",
    ")\n",
    "```\n",
    "\n",
    "**ToDo Task:**\n",
    "```python\n",
    "task = ToDo(\n",
    "    task=\"Finish project report\",\n",
    "    time_to_complete=120,\n",
    "    deadline=datetime(2024, 12, 31, 17, 0),\n",
    "    solutions=[\"Draft outline\", \"Add visuals\", \"Proofread\"],\n",
    "    status=\"in progress\"\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "#### How It Fits in the Code\n",
    "- The **Profile** schema supports **personalization** by storing user information.  \n",
    "- The **ToDo** schema manages **tasks and updates**, enabling the chatbot to **track progress** and suggest solutions.  \n",
    "- Both schemas integrate with TrustCall to **extract, update, and store memories** automatically during conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d07cc2a-5030-4ac1-bafb-2d268965eae6",
   "metadata": {},
   "source": [
    "## The TrustCall Extractor is so easy that it does not require explanation\n",
    "* As you can see in the code, there is nothing new in the extractor definition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d22dbb-88b6-45fb-9ab3-8f8e478d95ab",
   "metadata": {},
   "source": [
    "## That was very interesting. Now let's review the segment where we give instructions for the chatbot\n",
    "\n",
    "This segment of the code defines **instructions for the chatbot** to guide its behavior when interacting with the user. It ensures the chatbot knows how to **analyze messages**, **decide what to update**, and **respond appropriately**. Here's a simple explanation of each part:\n",
    "\n",
    "#### Chatbot Instructions (`MODEL_SYSTEM_MESSAGE`):\n",
    "This section defines the chatbot's **role and rules** for processing conversations.  \n",
    "\n",
    "- **Role:**  \n",
    "  The chatbot is a **helpful assistant** designed to:\n",
    "  1. Keep track of the user's **profile** (personal info).  \n",
    "  2. Manage the user's **ToDo list** (tasks).  \n",
    "  3. Follow **preferences** for updating tasks (instructions).  \n",
    "\n",
    "- **Data Context:**  \n",
    "  The chatbot is given the **current state** of:  \n",
    "  - **User Profile:** Details about the user.  \n",
    "  - **ToDo List:** List of tasks.  \n",
    "  - **Instructions:** Preferences for task management.  \n",
    "\n",
    "- **Decision Rules:**  \n",
    "  The chatbot analyzes user messages and decides:  \n",
    "  1. **Update Profile:** If the user shares personal info (e.g., name, location).  \n",
    "  2. **Update ToDo List:** If tasks or deadlines are mentioned.  \n",
    "  3. **Update Instructions:** If preferences about task updates are specified.  \n",
    "\n",
    "- **Responses:**  \n",
    "  - **Notify** the user about **ToDo updates**.  \n",
    "  - **Do not notify** about **profile** or **instruction updates** to avoid interrupting the flow.  \n",
    "  - Always **prioritize updating the ToDo list** without asking for permission.  \n",
    "\n",
    "- **Final Rule:**  \n",
    "  After analyzing the input, **respond naturally** to continue the conversation—whether updates are made or not.\n",
    "\n",
    "\n",
    "#### TrustCall Instruction (`TRUSTCALL_INSTRUCTION`) \n",
    "This is an **instruction template** for TrustCall to handle memory updates efficiently.  \n",
    "\n",
    "- **Purpose:**  \n",
    "  It tells TrustCall to:\n",
    "  1. **Analyze the interaction** and decide what data to save.  \n",
    "  2. Use **parallel tool calls** to **update multiple memories** (e.g., profile and tasks) at the same time.  \n",
    "\n",
    "- **System Time Placeholder:**  \n",
    "  It includes the **current time** to provide context for updates (useful for tracking deadlines).\n",
    "\n",
    "\n",
    "#### ToDo Update Instructions (`CREATE_INSTRUCTIONS`) \n",
    "This template is used for **adjusting instructions** on how the chatbot should manage ToDo list updates.  \n",
    "\n",
    "- **Purpose:**  \n",
    "  Based on **user feedback**, the chatbot can:\n",
    "  1. **Modify rules** for adding or updating tasks.  \n",
    "  2. **Reflect preferences**, such as how detailed tasks should be or whether reminders are needed.  \n",
    "\n",
    "- **Current Instructions Placeholder:**  \n",
    "  It includes the **existing instructions** as context and allows the chatbot to **refine them** based on recent interactions.\n",
    "\n",
    "\n",
    "#### Simplified Example Workflow\n",
    "\n",
    "**User:**  \n",
    "*\"I need to book a flight for next week and also follow up on my visa application.\"*  \n",
    "\n",
    "**Chatbot Actions:**  \n",
    "1. Detects **tasks** → Updates ToDo list.  \n",
    "2. Prioritizes updating the ToDo list without asking for confirmation.  \n",
    "3. Responds: *\"I've added 'Book a flight for next week' and 'Follow up on visa application' to your ToDo list.\"*  \n",
    "\n",
    "**User Later:**  \n",
    "*\"Remind me about these tasks a day before the deadlines.\"*  \n",
    "\n",
    "**Chatbot Actions:**  \n",
    "1. Updates **instructions** based on the request.  \n",
    "2. Does **not notify** the user about this update but uses it for future reminders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcf6764-f5a5-41cf-a55b-eca17d7989a0",
   "metadata": {},
   "source": [
    "## Excellent. Now let's review the segment where we define the nodes.\n",
    "\n",
    "This segment defines **four functions** (called **nodes**) that handle different tasks in the chatbot's **memory management system**. Each function is responsible for **updating a specific type of memory** (profile, ToDo list, or instructions) or **processing user input** to decide what needs updating.\n",
    "\n",
    "#### NODE `task_mAIstro`: Load Memories and Generate a Response \n",
    "\n",
    "**What it does:**\n",
    "- **Purpose:**  \n",
    "  Loads existing memories (profile, tasks, instructions) and **personalizes responses** based on the user's data.  \n",
    "\n",
    "**Steps:**\n",
    "1. **Identify the User:**  \n",
    "   Gets the **user ID** from the configuration to fetch their data.  \n",
    "\n",
    "2. **Retrieve Memories:**  \n",
    "   - **Profile:** Loads saved user info like name or location.  \n",
    "   - **ToDo List:** Loads tasks and deadlines.  \n",
    "   - **Instructions:** Loads preferences for managing tasks.  \n",
    "\n",
    "3. **Prepare System Message:**  \n",
    "   Formats the chatbot's **system message** with the user's current data.  \n",
    "\n",
    "4. **Respond to the User:**  \n",
    "   Uses the **chat model** to generate a response, taking the user's messages and saved memories into account.  \n",
    "\n",
    "**Output:**  \n",
    "Returns the chatbot's **response message** to continue the conversation.  \n",
    "\n",
    "\n",
    "#### NODE `update_profile`: Update User Profile\n",
    "\n",
    "**What it does:**\n",
    "- **Purpose:**  \n",
    "  Checks if the user mentioned any **personal information** (e.g., name, job) and **updates their profile**.  \n",
    "\n",
    "**Steps:**\n",
    "1. **Retrieve Existing Profile:**  \n",
    "   Fetches the saved profile data for context.  \n",
    "\n",
    "2. **Prepare Messages:**  \n",
    "   Combines the chat history and instructions for TrustCall to analyze the messages.  \n",
    "\n",
    "3. **Extract New Info:**  \n",
    "   Uses the **TrustCall extractor** to detect and extract **new profile details**.  \n",
    "\n",
    "4. **Save Profile Updates:**  \n",
    "   Stores the **new or updated profile** in the memory database.  \n",
    "\n",
    "5. **Notify the Chatbot:**  \n",
    "   Confirms that the profile was updated (but does **not inform the user** directly).  \n",
    "\n",
    "**Output:**  \n",
    "Returns a **tool message** confirming the update to the chatbot, which it uses internally.  \n",
    "\n",
    "\n",
    "#### NODE `update_todos`: Update ToDo List\n",
    "\n",
    "**Note: the update_todos node uses the extract_tool_info function**\n",
    "* We explain in simple terms the extract_tool_info function in the section below.\n",
    "\n",
    "**What it does:**\n",
    "- **Purpose:**  \n",
    "  Detects and **updates tasks** in the user's ToDo list based on the conversation.  \n",
    "\n",
    "**Steps:**\n",
    "1. **Retrieve Existing Tasks:**  \n",
    "   Loads saved tasks to check for updates or additions.  \n",
    "\n",
    "2. **Prepare Messages:**  \n",
    "   Formats the chat history and instructions for TrustCall analysis.  \n",
    "\n",
    "3. **Spy on Tool Calls:**  \n",
    "   Adds a **Spy** to track tool calls made by TrustCall for debugging purposes.  \n",
    "\n",
    "4. **Extract Task Updates:**  \n",
    "   Uses the **TrustCall extractor** to identify **new or updated tasks** and stores them.  \n",
    "\n",
    "5. **Notify the Chatbot and User:**  \n",
    "   Confirms updates to the ToDo list and **informs the user** about the changes.  \n",
    "\n",
    "**Output:**  \n",
    "Returns a **tool message** summarizing the updates to the chatbot, which it relays to the user.  \n",
    "\n",
    "\n",
    "#### NODE `update_instructions`: Update Task Management Preferences\n",
    "\n",
    "**What it does:**\n",
    "- **Purpose:**  \n",
    "  Updates the chatbot's **instructions** for managing tasks based on user preferences.  \n",
    "\n",
    "**Steps:**\n",
    "1. **Retrieve Current Instructions:**  \n",
    "   Loads existing preferences, if any.  \n",
    "\n",
    "2. **Prepare Message:**  \n",
    "   Formats a prompt to **reflect and update preferences** based on the latest interaction.  \n",
    "\n",
    "3. **Generate Updated Instructions:**  \n",
    "   Uses the **chat model** to create **revised instructions** for handling tasks.  \n",
    "\n",
    "4. **Save the Updates:**  \n",
    "   Overwrites the **existing instructions** in memory with the new version.  \n",
    "\n",
    "5. **Notify the Chatbot:**  \n",
    "   Confirms that the instructions were updated (but does **not notify the user**).  \n",
    "\n",
    "**Output:**  \n",
    "Returns a **tool message** confirming the update to the chatbot for internal use.  \n",
    "\n",
    "\n",
    "#### Overall Purpose of the Nodes\n",
    "These functions:\n",
    "1. **Load and analyze data** stored in memory.  \n",
    "2. **Decide what needs updating** based on user input (profile, tasks, or instructions).  \n",
    "3. **Update and save memories** using TrustCall extractors.  \n",
    "4. **Inform the chatbot** (and sometimes the user) about updates to keep conversations context-aware.  \n",
    "\n",
    "\n",
    "#### Simplified Example Workflow\n",
    "\n",
    "**User:**  \n",
    "*\"I moved to New York and need to book a flight by Friday.\"*  \n",
    "\n",
    "**Step-by-Step Process:**\n",
    "1. **`task_mAIstro`:**  \n",
    "   Detects the user mentioned a new **location** and a **task**.  \n",
    "\n",
    "2. **`update_profile`:**  \n",
    "   Updates the **profile** with \"New York\" as the location.  \n",
    "\n",
    "3. **`update_todos`:**  \n",
    "   Adds \"Book a flight by Friday\" to the **ToDo list** and **notifies the user**.  \n",
    "\n",
    "4. **`update_instructions`:**  \n",
    "   Checks if the user specified preferences (e.g., reminders) and **updates instructions** if needed.  \n",
    "\n",
    "**Chatbot Response:**  \n",
    "*\"I've added 'Book a flight by Friday' to your ToDo list.\"*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473388f9-de32-4d8c-923b-0f50c149010c",
   "metadata": {},
   "source": [
    "## Line-by-Line Explanation of `task_mAIstro` Function\n",
    "The `task_mAIstro` function is the main node in the LangGraph workflow that retrieves stored information about the user and their tasks, and then generates a response based on that information.\n",
    "\n",
    "\n",
    "#### Function Definition\n",
    "```python\n",
    "def task_mAIstro(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "```\n",
    "- **`state`**: Holds the chat history (messages between the user and the chatbot).\n",
    "- **`config`**: Contains additional configuration settings (like the user ID).\n",
    "- **`store`**: Stores long-term memory, such as user profile data and tasks.\n",
    "\n",
    "\n",
    "#### Step 1: Get the User ID\n",
    "```python\n",
    "user_id = config[\"configurable\"][\"user_id\"]\n",
    "```\n",
    "- Extracts the **user's unique identifier** from the configuration.\n",
    "- This ID is used to **retrieve the correct user data** from storage.\n",
    "\n",
    "\n",
    "#### Step 2: Retrieve User Profile\n",
    "```python\n",
    "namespace = (\"profile\", user_id)\n",
    "memories = store.search(namespace)\n",
    "if memories:\n",
    "    user_profile = memories[0].value\n",
    "else:\n",
    "    user_profile = None\n",
    "```\n",
    "- **Searches the memory store** for any saved **profile information** (e.g., name, location, job, interests).\n",
    "- If a profile exists, it is assigned to `user_profile`.\n",
    "- If **no profile** is found, it is set to `None`.\n",
    "\n",
    "\n",
    "#### Step 3: Retrieve To-Do List\n",
    "```python\n",
    "namespace = (\"todo\", user_id)\n",
    "memories = store.search(namespace)\n",
    "todo = \"\\n\".join(f\"{mem.value}\" for mem in memories)\n",
    "```\n",
    "- **Searches the memory store** for the user's saved **To-Do list**.\n",
    "- Converts the stored tasks into a **single formatted string**.\n",
    "\n",
    "\n",
    "#### Step 4: Retrieve User Preferences\n",
    "```python\n",
    "namespace = (\"instructions\", user_id)\n",
    "memories = store.search(namespace)\n",
    "if memories:\n",
    "    instructions = memories[0].value\n",
    "else:\n",
    "    instructions = \"\"\n",
    "```\n",
    "- **Searches the memory store** for any saved **user preferences** related to task updates.\n",
    "- If preferences exist, they are assigned to `instructions`, otherwise, it is set to an empty string.\n",
    "\n",
    "\n",
    "#### Step 5: Format the System Message\n",
    "```python\n",
    "system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, todo=todo, instructions=instructions)\n",
    "```\n",
    "- **Fills in the system message template** (`MODEL_SYSTEM_MESSAGE`) with:\n",
    "  - The user’s **profile**.\n",
    "  - Their **To-Do list**.\n",
    "  - Their **task update preferences**.\n",
    "- This ensures the chatbot **has context** before responding.\n",
    "\n",
    "\n",
    "#### Step 6: Generate a Response\n",
    "```python\n",
    "response = model.bind_tools([UpdateMemory], parallel_tool_calls=False).invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "```\n",
    "- Calls the **AI model (`gpt-4o`)** to process the user's message **along with the retrieved memory**.\n",
    "- Uses **`UpdateMemory` tool** to handle any necessary memory updates.\n",
    "- The **`invoke` function** sends the **system message + conversation history** to the model.\n",
    "- The AI **generates a response** based on the stored information.\n",
    "\n",
    "\n",
    "#### Step 7: Return the Response\n",
    "```python\n",
    "return {\"messages\": [response]}\n",
    "```\n",
    "- The chatbot’s **generated response** is **returned**.\n",
    "- This response will be sent **back to the user** in the conversation.\n",
    "\n",
    "\n",
    "#### Summary of What `task_mAIstro` Does\n",
    "1. **Retrieves user data** (profile, tasks, preferences) from memory.\n",
    "2. **Formats a system message** with this information.\n",
    "3. **Sends the formatted message + chat history** to the AI model.\n",
    "4. **Generates and returns a chatbot response**.\n",
    "\n",
    "This function ensures that the chatbot **remembers past conversations** and **responds in a personalized way**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7357a4-986f-457f-8ff1-1cdc5f460f44",
   "metadata": {},
   "source": [
    "## Line-by-Line Explanation of `update_profile` Function\n",
    "The `update_profile` function **analyzes the chat history** and **updates the user's profile information** in the long-term memory store.\n",
    "\n",
    "\n",
    "#### Function Definition\n",
    "```python\n",
    "def update_profile(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "```\n",
    "- **`state`**: Holds the conversation history (messages exchanged between the user and the chatbot).\n",
    "- **`config`**: Configuration settings (includes user ID).\n",
    "- **`store`**: The **memory storage system** where user profiles are saved.\n",
    "\n",
    "\n",
    "#### Step 1: Get the User ID\n",
    "```python\n",
    "user_id = config[\"configurable\"][\"user_id\"]\n",
    "```\n",
    "- Extracts the **user's unique identifier**.\n",
    "- This ID helps retrieve and update the **correct user's profile**.\n",
    "\n",
    "\n",
    "#### Step 2: Define Where Profile Data is Stored\n",
    "```python\n",
    "namespace = (\"profile\", user_id)\n",
    "```\n",
    "- Creates a **namespace** (a label) for storing **profile-related data**.\n",
    "- This ensures profile updates are saved under the correct category.\n",
    "\n",
    "\n",
    "#### Step 3: Retrieve Existing Profile Information\n",
    "```python\n",
    "existing_items = store.search(namespace)\n",
    "```\n",
    "- **Checks if any profile information already exists** in memory.\n",
    "- If the user **has shared profile details before**, they will be stored in `existing_items`.\n",
    "\n",
    "\n",
    "#### Step 4: Format Profile Data for Processing\n",
    "```python\n",
    "tool_name = \"Profile\"\n",
    "existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                      for existing_item in existing_items]\n",
    "                      if existing_items\n",
    "                      else None\n",
    "                    )\n",
    "```\n",
    "- If there are **existing profile details**, they are **formatted** into a structured list.\n",
    "- If **no profile data exists**, it is set to `None`.\n",
    "\n",
    "\n",
    "#### Step 5: Prepare the System Instruction\n",
    "```python\n",
    "TRUSTCALL_INSTRUCTION_FORMATTED = TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat())\n",
    "```\n",
    "- Formats the **system instruction template** (`TRUSTCALL_INSTRUCTION`) by inserting the **current timestamp**.\n",
    "- This instruction helps the AI understand what to do with the new user input.\n",
    "\n",
    "\n",
    "#### Step 6: Merge Chat History for Processing\n",
    "```python\n",
    "updated_messages = list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "```\n",
    "- **Merges** the **instruction** with the user's latest messages.\n",
    "- The function **excludes the very last message** in `state[\"messages\"]` because that one is the tool call itself.\n",
    "\n",
    "\n",
    "#### Step 7: Extract Updated Profile Information\n",
    "```python\n",
    "result = profile_extractor.invoke({\"messages\": updated_messages, \n",
    "                                   \"existing\": existing_memories})\n",
    "```\n",
    "- Calls the **profile extractor** (`profile_extractor`) to analyze the messages.\n",
    "- **Identifies new profile details** from the user's conversation.\n",
    "- Uses **existing profile data (if any)** for context.\n",
    "\n",
    "\n",
    "#### Step 8: Store the Updated Profile Information\n",
    "```python\n",
    "for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "    store.put(namespace,\n",
    "              rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "              r.model_dump(mode=\"json\"),\n",
    "    )\n",
    "```\n",
    "- **Loops through extracted profile updates**.\n",
    "- **Saves the updated profile** in the memory store (`store.put()`).\n",
    "- If the update does not have an ID, a new **UUID** (unique identifier) is generated.\n",
    "\n",
    "\n",
    "#### Step 9: Send a Confirmation Message\n",
    "```python\n",
    "tool_calls = state['messages'][-1].tool_calls\n",
    "return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated profile\", \"tool_call_id\": tool_calls[0]['id']}]}\n",
    "```\n",
    "- Retrieves the **original tool call ID** to link the update to the correct request.\n",
    "- **Returns a response** to confirm the profile has been updated.\n",
    "\n",
    "\n",
    "#### Summary of What `update_profile` Does\n",
    "1. **Retrieves the user’s profile data** (if available).\n",
    "2. **Formats the profile data** for processing.\n",
    "3. **Prepares an instruction message** to guide AI extraction.\n",
    "4. **Analyzes chat history** to find new profile updates.\n",
    "5. **Stores any extracted profile updates** in memory.\n",
    "6. **Returns a confirmation message** that the update was successful.\n",
    "\n",
    "This function ensures the chatbot **remembers user details** (name, location, interests, etc.) and **keeps them up-to-date**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e8fb9-7406-4c3f-82aa-0c2bec75e209",
   "metadata": {},
   "source": [
    "## About the extract_tool_info function used by the update_todos Node\n",
    "\n",
    "We needed to add the helper function **`extract_tool_info`** in order for this code to work. **It was not originally in the project prepared by the LangGraph team**. This function is used to analyze and summarize information about tool calls (actions taken by the system to update or manage data). Here's a simple explanation about the coding of this function (you can see the code before the update_todos node):\n",
    "\n",
    "#### What does it do?\n",
    "The function:\n",
    "1. **Takes Input**: \n",
    "   - A list of tool calls (`tool_calls`) made during the chatbot's process.\n",
    "   - The name of a specific tool (`tool_name`) that we are interested in analyzing.\n",
    "2. **Finds Relevant Tool Calls**:\n",
    "   - It loops through all tool calls to check if the tool name matches the one specified.\n",
    "3. **Extracts Information**:\n",
    "   - For matching tool calls, it collects details about what arguments or updates were made using that tool.\n",
    "4. **Formats a Summary**:\n",
    "   - Creates a human-readable summary of the updates made by the tool.\n",
    "   - If no updates were found, it returns a message saying so.\n",
    "\n",
    "#### Step-by-Step Explanation\n",
    "1. **Initialize an Empty List**:\n",
    "   - `updates = []`: This list will store the summary of updates for the specified tool.\n",
    "\n",
    "2. **Loop Through Tool Calls**:\n",
    "   ```python\n",
    "   for tool_call in tool_calls:\n",
    "   ```\n",
    "   - Each `tool_call` is checked to see if it contains updates.\n",
    "\n",
    "3. **Nested Loop for Individual Calls**:\n",
    "   ```python\n",
    "   for call in tool_call:\n",
    "   ```\n",
    "   - Each `call` within a `tool_call` is examined.\n",
    "\n",
    "4. **Match Tool Name**:\n",
    "   ```python\n",
    "   if call['name'] == tool_name:\n",
    "   ```\n",
    "   - If the `name` of the tool matches the specified `tool_name`, we process it.\n",
    "\n",
    "5. **Extract Arguments or Details**:\n",
    "   ```python\n",
    "   updates.append(f\"Updated {tool_name}: {call['args']}\")\n",
    "   ```\n",
    "   - Adds a summary like `\"Updated ToDo: {...}\"` to the `updates` list.\n",
    "\n",
    "6. **Return Results**:\n",
    "   ```python\n",
    "   return \"\\n\".join(updates) if updates else f\"No updates for {tool_name}.\"\n",
    "   ```\n",
    "   - If there are updates, it joins them into a single string separated by newlines.\n",
    "   - If no updates are found, it returns `\"No updates for {tool_name}.\"`\n",
    "\n",
    "\n",
    "#### Why is it important?\n",
    "- This function provides a **clear summary** of what actions were taken by a specific tool during a chatbot session.\n",
    "- It's helpful for:\n",
    "  - **Debugging**: To see how tools were used and what updates they made.\n",
    "  - **User Feedback**: To inform users about changes (e.g., updated ToDo list).\n",
    "\n",
    "\n",
    "#### Example\n",
    "Suppose the chatbot made these tool calls:\n",
    "```python\n",
    "tool_calls = [\n",
    "    [{'name': 'ToDo', 'args': {'task': 'Buy groceries', 'status': 'done'}}],\n",
    "    [{'name': 'Profile', 'args': {'name': 'Julio', 'location': 'Madrid'}}],\n",
    "]\n",
    "```\n",
    "\n",
    "If you call:\n",
    "```python\n",
    "extract_tool_info(tool_calls, 'ToDo')\n",
    "```\n",
    "\n",
    "It will return:\n",
    "```\n",
    "\"Updated ToDo: {'task': 'Buy groceries', 'status': 'done'}\"\n",
    "```\n",
    "\n",
    "If no `ToDo` updates were found, it would return:\n",
    "```\n",
    "\"No updates for ToDo.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a6352-3ef5-4d50-b3ac-df20b2e9cfa9",
   "metadata": {},
   "source": [
    "## Line-by-Line Explanation of `update_todos` Function\n",
    "The `update_todos` function **analyzes the chat history** and **updates the user's To-Do list** in the long-term memory store.\n",
    "\n",
    "\n",
    "#### Function Definition\n",
    "```python\n",
    "def update_todos(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "```\n",
    "- **`state`**: Holds the conversation history (messages between the user and the chatbot).\n",
    "- **`config`**: Contains configuration settings (including the user ID).\n",
    "- **`store`**: The **long-term memory storage system** where To-Do tasks are saved.\n",
    "\n",
    "\n",
    "#### Step 1: Get the User ID\n",
    "```python\n",
    "user_id = config[\"configurable\"][\"user_id\"]\n",
    "```\n",
    "- Retrieves the **user's unique identifier**.\n",
    "- This ID is used to **fetch and update the user's To-Do list**.\n",
    "\n",
    "\n",
    "#### Step 2: Define Where To-Do Data is Stored\n",
    "```python\n",
    "namespace = (\"todo\", user_id)\n",
    "```\n",
    "- Defines a **namespace** for storing **To-Do list items**.\n",
    "- This ensures tasks are saved in the correct category.\n",
    "\n",
    "\n",
    "#### Step 3: Retrieve Existing To-Do List\n",
    "```python\n",
    "existing_items = store.search(namespace)\n",
    "```\n",
    "- Searches the memory store for **previously saved tasks**.\n",
    "- If the user **already has tasks**, they will be stored in `existing_items`.\n",
    "\n",
    "\n",
    "#### Step 4: Format Existing Tasks for Processing\n",
    "```python\n",
    "tool_name = \"ToDo\"\n",
    "existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                      for existing_item in existing_items]\n",
    "                      if existing_items\n",
    "                      else None\n",
    "                    )\n",
    "```\n",
    "- If there are **existing tasks**, they are **formatted** into a structured list.\n",
    "- If **no tasks** exist, it is set to `None`.\n",
    "\n",
    "\n",
    "#### Step 5: Prepare the System Instruction\n",
    "```python\n",
    "TRUSTCALL_INSTRUCTION_FORMATTED = TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat())\n",
    "```\n",
    "- Formats the **system instruction template** (`TRUSTCALL_INSTRUCTION`) by inserting the **current timestamp**.\n",
    "- This instruction helps the AI **understand how to process the new To-Do list updates**.\n",
    "\n",
    "\n",
    "#### Step 6: Merge Chat History for Processing\n",
    "```python\n",
    "updated_messages = list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "```\n",
    "- **Merges** the **instruction** with the user's recent messages.\n",
    "- The function **excludes the very last message** in `state[\"messages\"]` because that one is the tool call itself.\n",
    "\n",
    "\n",
    "#### Step 7: Initialize a Spy (for Debugging)\n",
    "```python\n",
    "spy = Spy()\n",
    "```\n",
    "- Creates a **spy object** to track the AI model’s tool calls.\n",
    "- This is useful for **debugging and verifying updates**.\n",
    "\n",
    "\n",
    "#### Step 8: Create the To-Do Extractor\n",
    "```python\n",
    "todo_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[ToDo],\n",
    "    tool_choice=tool_name,\n",
    "    enable_inserts=True\n",
    ").with_listeners(on_end=spy)\n",
    "```\n",
    "- **Creates an AI-powered tool (`todo_extractor`)** that can:\n",
    "  - Extract new tasks from the chat.\n",
    "  - Update existing tasks.\n",
    "  - Insert new tasks into the To-Do list.\n",
    "- The `spy` is attached to **monitor updates**.\n",
    "\n",
    "\n",
    "#### Step 9: Extract To-Do List Updates\n",
    "```python\n",
    "result = todo_extractor.invoke({\"messages\": updated_messages, \n",
    "                                \"existing\": existing_memories})\n",
    "```\n",
    "- Calls the AI tool to **analyze the chat** and **identify To-Do updates**.\n",
    "- Uses **previous tasks (if any) for context**.\n",
    "\n",
    "\n",
    "#### Step 10: Store Updated Tasks\n",
    "```python\n",
    "for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "    store.put(namespace,\n",
    "              rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "              r.model_dump(mode=\"json\"),\n",
    "    )\n",
    "```\n",
    "- **Loops through the extracted task updates**.\n",
    "- **Saves the updated To-Do list** in memory.\n",
    "- If a task **does not have an ID**, a new **UUID** (unique identifier) is created.\n",
    "\n",
    "\n",
    "#### Step 11: Retrieve the Original Tool Call\n",
    "```python\n",
    "tool_calls = state['messages'][-1].tool_calls\n",
    "```\n",
    "- Retrieves the **original tool call ID** to link the update to the correct request.\n",
    "\n",
    "\n",
    "#### Step 12: Extract and Summarize Updates\n",
    "```python\n",
    "todo_update_msg = extract_tool_info(spy.called_tools, tool_name)\n",
    "```\n",
    "- Uses the `extract_tool_info` function to **summarize what changes were made**.\n",
    "- This ensures the chatbot **can inform the user of the update**.\n",
    "\n",
    "\n",
    "#### Step 13: Return a Confirmation Message\n",
    "```python\n",
    "return {\"messages\": [{\"role\": \"tool\", \"content\": todo_update_msg, \"tool_call_id\": tool_calls[0]['id']}]}\n",
    "```\n",
    "- **Returns a response** confirming the To-Do list update.\n",
    "- This **notifies the chatbot** that the task update was successful.\n",
    "\n",
    "\n",
    "#### Summary of What `update_todos` Does\n",
    "1. **Retrieves the user’s To-Do list** (if available).\n",
    "2. **Formats the existing tasks** for AI processing.\n",
    "3. **Prepares a system instruction** for analyzing task updates.\n",
    "4. **Merges recent chat history** for context.\n",
    "5. **Uses an AI tool to extract To-Do updates** from the conversation.\n",
    "6. **Stores the updated tasks** in the long-term memory.\n",
    "7. **Summarizes the changes** for the chatbot.\n",
    "8. **Returns a confirmation message** that the update was successful.\n",
    "\n",
    "This function ensures that the chatbot **remembers and updates the user's tasks** effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ebb550-cfdf-4779-be39-f7c9980529cc",
   "metadata": {},
   "source": [
    "## Line-by-Line Explanation of `update_instructions` Function\n",
    "The `update_instructions` function **analyzes the chat history** and **updates the user's preferences** for how their To-Do list should be managed.\n",
    "\n",
    "\n",
    "#### Function Definition\n",
    "```python\n",
    "def update_instructions(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "```\n",
    "- **`state`**: Contains the conversation history (messages between the user and the chatbot).\n",
    "- **`config`**: Includes configuration settings (like the user ID).\n",
    "- **`store`**: The **long-term memory storage** where To-Do preferences are saved.\n",
    "\n",
    "\n",
    "#### Step 1: Get the User ID\n",
    "```python\n",
    "user_id = config[\"configurable\"][\"user_id\"]\n",
    "```\n",
    "- Retrieves the **user's unique identifier**.\n",
    "- This ID is used to **fetch and update the user's To-Do list preferences**.\n",
    "\n",
    "\n",
    "#### Step 2: Define Where To-Do Preferences Are Stored\n",
    "```python\n",
    "namespace = (\"instructions\", user_id)\n",
    "```\n",
    "- Defines a **namespace** for storing **task management preferences**.\n",
    "- This ensures **preferences are saved in the correct category**.\n",
    "\n",
    "\n",
    "#### Step 3: Retrieve Existing To-Do Preferences\n",
    "```python\n",
    "existing_memory = store.get(namespace, \"user_instructions\")\n",
    "```\n",
    "- Searches the **memory store** for **previously saved user instructions** on how they prefer tasks to be updated.\n",
    "- If the user **has provided preferences before**, they are stored in `existing_memory`.\n",
    "\n",
    "\n",
    "#### Step 4: Format the Current Preferences\n",
    "```python\n",
    "system_msg = CREATE_INSTRUCTIONS.format(current_instructions=existing_memory.value if existing_memory else None)\n",
    "```\n",
    "- Uses a **template (`CREATE_INSTRUCTIONS`)** to **generate a system message**.\n",
    "- Inserts **the existing preferences** (if any) or sets them to `None` if none exist.\n",
    "- This system message **guides the AI on how to process user instructions**.\n",
    "\n",
    "\n",
    "#### Step 5: Generate Updated Instructions\n",
    "```python\n",
    "new_memory = model.invoke([SystemMessage(content=system_msg)] + state['messages'][:-1] + [HumanMessage(content=\"Please update the instructions based on the conversation\")])\n",
    "```\n",
    "- Sends **a request to the AI model (`gpt-4o`)** to:\n",
    "  - Analyze the **chat history**.\n",
    "  - Understand **how the user wants their tasks managed**.\n",
    "  - Generate **updated instructions** based on the conversation.\n",
    "- **How it works:**\n",
    "  - The **system message** (with old instructions) is sent first.\n",
    "  - The **user's chat history** is added next.\n",
    "  - A final message **explicitly asks the AI to update the instructions**.\n",
    "\n",
    "\n",
    "#### Step 6: Save the Updated Preferences\n",
    "```python\n",
    "key = \"user_instructions\"\n",
    "store.put(namespace, key, {\"memory\": new_memory.content})\n",
    "```\n",
    "- Saves the **updated instructions** into the memory store under `\"user_instructions\"`.\n",
    "\n",
    "\n",
    "#### Step 7: Retrieve the Original Tool Call\n",
    "```python\n",
    "tool_calls = state['messages'][-1].tool_calls\n",
    "```\n",
    "- Retrieves the **original tool call ID** so the update can be linked to the correct request.\n",
    "\n",
    "\n",
    "#### Step 8: Return a Confirmation Message\n",
    "```python\n",
    "return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated instructions\", \"tool_call_id\": tool_calls[0]['id']}]}\n",
    "```\n",
    "- Returns a **confirmation response** stating that the **instructions have been updated**.\n",
    "- This ensures the chatbot **acknowledges the update** and continues working with the new preferences.\n",
    "\n",
    "\n",
    "#### Summary of What `update_instructions` Does\n",
    "1. **Retrieves the user’s To-Do list preferences** (if available).\n",
    "2. **Formats a system message** with the current preferences.\n",
    "3. **Merges recent chat history** for context.\n",
    "4. **Asks the AI model to generate updated instructions**.\n",
    "5. **Stores the updated instructions** in long-term memory.\n",
    "6. **Returns a confirmation message** that the update was successful.\n",
    "\n",
    "This function ensures that the chatbot **adapts to how the user wants their tasks to be managed**, making interactions more personalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd29cc-7668-466e-b9c4-bc5d15cc9cef",
   "metadata": {},
   "source": [
    "## Good. Now let's review the segment where we define the Router\n",
    "\n",
    "This segment of the code defines a **decision-making function** called `route_message`. It **analyzes the user's latest message** and **decides what action the chatbot should take next**.  \n",
    "\n",
    "\n",
    "#### Purpose\n",
    "The function **routes the conversation flow** based on the type of information detected in the user's message (e.g., profile update, task update, or instructions update).\n",
    "\n",
    "\n",
    "#### What It Does \n",
    "\n",
    "1. **Check the Latest Message:**  \n",
    "   - Retrieves the **last message** from the chat history (`state['messages'][-1]`).  \n",
    "   - Looks for any **tool calls** (special actions triggered by the chatbot: in our case, the 3 types of updates).  \n",
    "\n",
    "2. **No Tool Calls? End the Process:**  \n",
    "   - If the message has **no tool calls** (the 3 types of updates), it **ends** the process (`return END`).  \n",
    "   - This means no updates to memory are needed, so the chatbot simply continues the conversation.  \n",
    "\n",
    "3. **Identify the Tool Call Type:**  \n",
    "   - If the message **does contain tool calls**, it **checks what type of update** is requested in the tool call.  \n",
    "\n",
    "4. **Decide the Next Action:**  \n",
    "   Based on the **update type**:\n",
    "   - `\"user\"` → Update the **user profile** (`return \"update_profile\"`).  \n",
    "   - `\"todo\"` → Update the **ToDo list** (`return \"update_todos\"`).  \n",
    "   - `\"instructions\"` → Update the **instructions** (`return \"update_instructions\"`).  \n",
    "   - **Else:** If the update type is **not recognized**, it raises an **error** (`ValueError`).  \n",
    "\n",
    "\n",
    "#### How It Fits into the Workflow\n",
    "\n",
    "- This function acts like a **traffic director** for the chatbot.  \n",
    "- After analyzing the user's message, it **decides which function (node) to run next**:\n",
    "  - **Profile updates** → `update_profile`.  \n",
    "  - **ToDo list updates** → `update_todos`.  \n",
    "  - **Instruction updates** → `update_instructions`.  \n",
    "  - **No updates needed** → Ends the process.  \n",
    "\n",
    "\n",
    "#### Example Workflow\n",
    "\n",
    "**User Message:**  \n",
    "*\"I need to add 'Submit tax report' to my tasks and update my location to Madrid.\"*  \n",
    "\n",
    "**Step-by-Step Process:**\n",
    "1. The chatbot detects **two tool calls**:  \n",
    "   - **Update ToDo** (task: \"Submit tax report\").  \n",
    "   - **Update Profile** (location: \"Madrid\").  \n",
    "\n",
    "2. The first tool call (`\"todo\"`) is processed → **route_message** directs the flow to `update_todos`.  \n",
    "\n",
    "3. Once the ToDo list is updated, the chatbot **loops back** and processes the next tool call (`\"user\"`), routing it to `update_profile`.  \n",
    "\n",
    "4. After processing both updates, the chatbot **resumes the conversation**.\n",
    "\n",
    "\n",
    "#### Key Takeaways \n",
    "\n",
    "- **Decides the Next Step:**  \n",
    "  Routes the chatbot to handle **profile, task, or instruction updates** based on the user's input.  \n",
    "\n",
    "- **Flexible and Context-Aware:**  \n",
    "  Allows the chatbot to **dynamically respond** to multiple types of updates without requiring predefined commands.  \n",
    "\n",
    "- **Error Handling:**  \n",
    "  Raises an error if an **unknown update type** is detected, ensuring **data integrity**.  \n",
    "\n",
    "This makes the chatbot **smart and adaptive**, capable of **multi-step processing** in a single conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778533ee-c00f-472c-aace-2985be211db2",
   "metadata": {},
   "source": [
    "## Line-by-Line Explanation of the `route_message` Function\n",
    "\n",
    "The `route_message` function is a conditional edge function in the LangGraph flow, which means it determines the next step in the workflow based on the last user interaction.\n",
    "\n",
    "#### Function Definition\n",
    "```python\n",
    "def route_message(state: MessagesState, config: RunnableConfig, store: BaseStore) -> Literal[END, \"update_todos\", \"update_instructions\", \"update_profile\"]:\n",
    "```\n",
    "- This function **takes in three arguments**:\n",
    "  - `state`: The current state of the conversation (contains message history).\n",
    "  - `config`: Configuration settings for the LangGraph execution.\n",
    "  - `store`: A storage system where long-term memory is maintained.\n",
    "- The function **returns one of four possible values**:\n",
    "  - `\"update_profile\"` → If user profile information needs updating.\n",
    "  - `\"update_todos\"` → If a task-related update is needed.\n",
    "  - `\"update_instructions\"` → If user preferences for updating tasks need modifying.\n",
    "  - `END` → If no update is required, the process stops.\n",
    "\n",
    "\n",
    "#### Step 1: Get the Last User Message\n",
    "```python\n",
    "message = state['messages'][-1]\n",
    "```\n",
    "- Retrieves the **latest message** from the conversation history.\n",
    "- This message is the basis for deciding what action to take next.\n",
    "\n",
    "\n",
    "#### Step 2: Check if There Are Any Tool Calls\n",
    "```python\n",
    "if len(message.tool_calls) == 0:\n",
    "    return END\n",
    "```\n",
    "- If **no tool calls** are present in the last message, **there's nothing to update**, so the function **ends the process**.\n",
    "\n",
    "\n",
    "#### Step 3: Get the First Tool Call\n",
    "```python\n",
    "else:\n",
    "    tool_call = message.tool_calls[0]\n",
    "```\n",
    "- If there are **tool calls** (i.e., some update is needed), the function **takes the first one** to process.\n",
    "\n",
    "\n",
    "#### Step 4: Determine the Update Type\n",
    "```python\n",
    "if tool_call['args']['update_type'] == \"user\":\n",
    "    return \"update_profile\"\n",
    "```\n",
    "- If the tool call specifies `\"user\"` in the `update_type`, the function **routes the process to `update_profile`**.\n",
    "- This means the user's profile (name, job, interests, etc.) needs an update.\n",
    "\n",
    "```python\n",
    "elif tool_call['args']['update_type'] == \"todo\":\n",
    "    return \"update_todos\"\n",
    "```\n",
    "- If `\"todo\"` is specified, the function **routes the process to `update_todos`**.\n",
    "- This means the user's ToDo list requires an update (adding/editing/deleting a task).\n",
    "\n",
    "```python\n",
    "elif tool_call['args']['update_type'] == \"instructions\":\n",
    "    return \"update_instructions\"\n",
    "```\n",
    "- If `\"instructions\"` is specified, the function **routes the process to `update_instructions`**.\n",
    "- This means the chatbot's **guidelines for managing the user's tasks** need updating.\n",
    "\n",
    "\n",
    "#### Step 5: Handle Unexpected Cases\n",
    "```python\n",
    "else:\n",
    "    raise ValueError\n",
    "```\n",
    "- If none of the expected update types are found, **an error is raised**.\n",
    "- This prevents unexpected behavior in case of invalid tool calls.\n",
    "\n",
    "\n",
    "#### Summary of What `route_message` Does\n",
    "1. **Checks the latest user message**.\n",
    "2. **If no update is needed**, the process ends (`END`).\n",
    "3. **If an update is needed**, it examines the tool call type:\n",
    "   - `\"user\"` → Update user profile (`update_profile`).\n",
    "   - `\"todo\"` → Update the ToDo list (`update_todos`).\n",
    "   - `\"instructions\"` → Update task management preferences (`update_instructions`).\n",
    "4. **If an invalid update type is found**, it raises an error.\n",
    "\n",
    "This function ensures that the chatbot correctly **routes memory updates** based on the user's interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf6e85c-fe00-4410-bf3e-e17f790a89dc",
   "metadata": {},
   "source": [
    "## And finally, let's review the segment where we define the agent workflow\n",
    "\n",
    "This segment of the code **creates and configures a flowchart-like structure** (called a **graph**) to control how the chatbot processes and updates its memory. It defines the **steps** (nodes) and **connections** (edges) between them, guiding the chatbot's decision-making process.\n",
    "\n",
    "\n",
    "#### Build the Graph (StateGraph)\n",
    "```python\n",
    "builder = StateGraph(MessagesState)\n",
    "```\n",
    "- **Purpose:** Sets up a **graph structure** to manage the chatbot's actions.  \n",
    "- **`MessagesState`:** Keeps track of the **current state of messages** during the conversation.\n",
    "\n",
    "\n",
    "#### Add Nodes (Steps) \n",
    "```python\n",
    "builder.add_node(task_mAIstro)\n",
    "builder.add_node(update_todos)\n",
    "builder.add_node(update_profile)\n",
    "builder.add_node(update_instructions)\n",
    "```\n",
    "- **Nodes = Actions** the chatbot can perform.  \n",
    "- Adds 4 nodes to the graph:\n",
    "  1. **`task_mAIstro`:** Decides what memory needs updating.  \n",
    "  2. **`update_todos`:** Updates the **ToDo list**.  \n",
    "  3. **`update_profile`:** Updates the **user profile**.  \n",
    "  4. **`update_instructions`:** Updates **task management preferences**.  \n",
    "\n",
    "\n",
    "#### Connect Nodes (Flow) \n",
    "\n",
    "**Start the Process:**\n",
    "```python\n",
    "builder.add_edge(START, \"task_mAIstro\")\n",
    "```\n",
    "- Starts at **`task_mAIstro`** to **analyze user input** and decide what to do next.\n",
    "\n",
    "**Make Decisions:**\n",
    "```python\n",
    "builder.add_conditional_edges(\"task_mAIstro\", route_message)\n",
    "```\n",
    "- **`route_message`:** Acts like a **traffic controller** to **direct the flow** based on the user's message.  \n",
    "  - If the user mentions a task → Go to **`update_todos`**.  \n",
    "  - If the user shares personal info → Go to **`update_profile`**.  \n",
    "  - If preferences are specified → Go to **`update_instructions`**.  \n",
    "  - Otherwise → **End the process**.\n",
    "\n",
    "**Loop Back for More Updates:**\n",
    "```python\n",
    "builder.add_edge(\"update_todos\", \"task_mAIstro\")\n",
    "builder.add_edge(\"update_profile\", \"task_mAIstro\")\n",
    "builder.add_edge(\"update_instructions\", \"task_mAIstro\")\n",
    "```\n",
    "- After **updating memory**, the chatbot **returns to the start** to **process more messages** if needed.  \n",
    "- This **looping behavior** allows the chatbot to **handle multiple updates** in one session.\n",
    "\n",
    "\n",
    "#### Set Up Memory Storage\n",
    "\n",
    "**Long-Term Memory:**\n",
    "```python\n",
    "across_thread_memory = InMemoryStore()\n",
    "```\n",
    "- Stores **long-term data** like the **user profile, ToDo list, and instructions**.  \n",
    "- Keeps this data **between conversations** so the chatbot **remembers past interactions**.\n",
    "\n",
    "**Short-Term Memory:**\n",
    "```python\n",
    "within_thread_memory = MemorySaver()\n",
    "```\n",
    "- Tracks **short-term data** during the **current chat session**.  \n",
    "- Useful for **temporary updates** and processing multiple tool calls.\n",
    "\n",
    "\n",
    "#### Compile the Graph\n",
    "```python\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "```\n",
    "- **Compiles the graph** into a **functional chatbot flow**.  \n",
    "- **Connects memory storage** to the chatbot, so it can **retrieve and update data** as needed.\n",
    "\n",
    "\n",
    "#### What the Graph Does\n",
    "\n",
    "**Example Workflow:**\n",
    "1. User: *\"I need to finish my report by Friday and my name is Alice.\"*  \n",
    "2. Starts at **`task_mAIstro`** → Analyzes the input.  \n",
    "3. Routes to **`update_todos`** → Adds the task \"Finish report by Friday.\"  \n",
    "4. Loops back → Routes to **`update_profile`** → Updates name to \"Alice.\"  \n",
    "5. Loops back again → Ends the process since no more updates are needed.  \n",
    "\n",
    "\n",
    "#### Key Takeaways\n",
    "- The **graph** is like a **map** that controls how the chatbot **processes user input** and **updates memory**.  \n",
    "- It **handles multiple updates** in one session by looping back to process more actions if needed.  \n",
    "- **Long-term memory** keeps track of user data over time, while **short-term memory** manages the current chat session.  \n",
    "- This design makes the chatbot **flexible, context-aware, and capable of learning** as conversations evolve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d61302d-89c7-4e8c-ba77-db5e9a9f8edb",
   "metadata": {},
   "source": [
    "## Wow, that sure was a looooong review! Time now to see the Agent at work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f97881-3170-4e60-855f-7e4f742e7e56",
   "metadata": {},
   "source": [
    "## Let's start our conversation with the ToDo Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b7e80af-cbdc-4954-b05a-2b2a69df5c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My name is Julio. I live in San Francisco.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_naNKe8eiOKIhLVpk7RCQPqA4)\n",
      " Call ID: call_naNKe8eiOKIhLVpk7RCQPqA4\n",
      "  Args:\n",
      "    update_type: user\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated profile\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Julio! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"Julio\"}}\n",
    "\n",
    "# User input to create a profile memory\n",
    "input_messages = [HumanMessage(content=\"My name is Julio. I live in San Francisco.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c662a-b4b2-429f-bc29-7145e5ac9ab5",
   "metadata": {},
   "source": [
    "## Let's explain in simple terms what we just did\n",
    "\n",
    "The previous code demonstrates how to use the memory system described earlier to process user input and update the chatbot's memory. Here's a breakdown in simple terms:\n",
    "\n",
    "#### What is it doing?\n",
    "\n",
    "1. **Set Up Configuration**\n",
    "   - A `config` dictionary is created with two identifiers:\n",
    "     - **`thread_id`**: Represents the current session or \"short-term memory.\"\n",
    "     - **`user_id`**: Identifies the user (in this case, \"Julio\") for \"long-term memory.\"\n",
    "\n",
    "2. **Provide User Input**\n",
    "   - The `input_messages` list contains the user's input. \n",
    "   - In this case, Julio shares personal details: `\"My name is Julio. I live in San Francisco.\"`\n",
    "\n",
    "3. **Run the Graph**\n",
    "   - The `graph.stream` function processes the input messages and updates the chatbot's memory system based on the defined workflow.\n",
    "\n",
    "4. **Stream Results**\n",
    "   - The `stream_mode=\"values\"` ensures that the graph outputs intermediate results as it processes the input.\n",
    "   - For each \"chunk\" (step of processing), the last message in `chunk[\"messages\"]` is printed in a readable format using `pretty_print()`.\n",
    "\n",
    "\n",
    "#### How does it work in practice?\n",
    "1. **User Input is Passed to the Graph**:\n",
    "   - The graph nodes (like `task_mAIstro`, `update_profile`, etc.) process the input message.\n",
    "   - It determines that the user's input contains personal information (name and location).\n",
    "\n",
    "2. **Memory Update**:\n",
    "   - The `update_profile` node is triggered because the input is relevant to the user's profile.\n",
    "   - A new memory entry is created for \"Julio\" with their name and location.\n",
    "\n",
    "3. **Output the Results**:\n",
    "   - The updated memory or response from the chatbot is streamed and displayed using `pretty_print()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf3b04f-8c53-47bc-9026-68ec3bf11a6a",
   "metadata": {},
   "source": [
    "## Fine. Let's now add our first task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cfe3ef8-ebd6-44ef-8eb3-110c21fa8c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Schedule interviews with candidates for California Sales Manager.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_lqjYq0pgzgoSlvTMLyAknKsy)\n",
      " Call ID: call_lqjYq0pgzgoSlvTMLyAknKsy\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Updated ToDo: {'task': 'Schedule interviews with candidates for California Sales Manager.', 'time_to_complete': 120, 'solutions': ['Use scheduling software like Calendly or Doodle to coordinate times.', 'Contact candidates via email or phone to confirm availability.', 'Coordinate with the hiring team to ensure their availability.'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added \"Schedule interviews with candidates for California Sales Manager\" to your ToDo list. Is there anything else you'd like to add or update?\n"
     ]
    }
   ],
   "source": [
    "# User input for a ToDo\n",
    "input_messages = [HumanMessage(content=\"Schedule interviews with candidates for California Sales Manager.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d57112-1fc5-42e9-bb52-e262b1ee324a",
   "metadata": {},
   "source": [
    "## See how that updated the todos memory. This is what we did.\n",
    "\n",
    "The previous code demonstrates how the chatbot processes a user's message related to a task and updates the **ToDo list** in its memory. Here's a simplified explanation:\n",
    "\n",
    "#### What does this code do?\n",
    "\n",
    "1. **User Input for a Task**\n",
    "   - The user provides a new message: `\"Schedule interviews with candidates for California Sales Manager.\"`\n",
    "   - This is interpreted as a task that the chatbot should add to its **ToDo list**.\n",
    "\n",
    "2. **Run the Graph**\n",
    "   - The `graph.stream` function processes the input message.\n",
    "   - It uses the workflow defined in the graph (e.g., nodes like `task_mAIstro` and `update_todos`) to decide how to handle the input.\n",
    "\n",
    "3. **Update the ToDo List**\n",
    "   - The workflow identifies that this input is related to a task.\n",
    "   - It triggers the `update_todos` node, which updates the user's **ToDo list** in memory by adding the task.\n",
    "\n",
    "4. **Stream Results**\n",
    "   - As the graph processes the input, it streams intermediate results in `stream_mode=\"values\"`.\n",
    "   - For each processing step, the last message is displayed in a user-friendly format using `pretty_print()`.\n",
    "\n",
    "\n",
    "#### How does it work?\n",
    "\n",
    "1. **Analyze the Input**:\n",
    "   - The chatbot recognizes that the input describes a task, not personal information or preferences.\n",
    "\n",
    "2. **Decide to Update ToDo List**:\n",
    "   - The system routes the input to the `update_todos` node.\n",
    "   - This node adds the task to the **ToDo list** memory under the user's ID (`Julio`).\n",
    "\n",
    "3. **Provide Feedback**:\n",
    "   - The chatbot may confirm the addition of the task by generating a response like:\n",
    "     ```\n",
    "     \"I've added 'Schedule interviews with candidates for California Sales Manager' to your ToDo list.\"\n",
    "     ```\n",
    "\n",
    "4. **Save to Memory**:\n",
    "   - The task is stored in the long-term memory, so it can be retrieved or updated later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87106b5-b8df-4b1e-8281-d4a90fd8bef7",
   "metadata": {},
   "source": [
    "## Good. Let's now tell the Agent how to behave and see if that updates the instructions memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b475d4e1-839d-44c5-8928-a43d3d82a14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "When creating or updating ToDo items, include if they are urgent or non-urgent. If I do not said anything about this matter, assume the task is not urgent.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_ZRFF0RPJTJjQVnM2R0sHWMJ4)\n",
      " Call ID: call_ZRFF0RPJTJjQVnM2R0sHWMJ4\n",
      "  Args:\n",
      "    update_type: instructions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated instructions\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it! I'll make sure to include whether tasks are urgent or non-urgent, and if you don't specify, I'll assume they're not urgent. How else can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# User input to update instructions for creating ToDos\n",
    "input_messages = [HumanMessage(content=\"When creating or updating ToDo items, include if they are urgent or non-urgent. If I do not said anything about this matter, assume the task is not urgent.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d10849b-1914-4a59-8368-9d5c0de0dde3",
   "metadata": {},
   "source": [
    "## That worked well. Let's see what we just did.\n",
    "\n",
    "The previous code demonstrates how the chatbot processes a user's message to update **instructions** for managing their **ToDo list**. Here's a simple explanation:\n",
    "\n",
    "#### What does the code do?\n",
    "\n",
    "1. **User Input to Update Instructions**\n",
    "   - The user provides a specific preference: \n",
    "     ```\n",
    "     \"When creating or updating ToDo items, include if they are urgent or non-urgent. If I do not say anything about this matter, assume the task is not urgent.\"\n",
    "     ```\n",
    "   - This input tells the chatbot how to handle urgency when creating or updating ToDo tasks.\n",
    "\n",
    "2. **Run the Graph**\n",
    "   - The `graph.stream` function processes the message.\n",
    "   - It uses the workflow defined in the graph to determine that the input relates to **instructions** for managing the **ToDo list**.\n",
    "\n",
    "3. **Update Instructions**\n",
    "   - The workflow identifies that this input specifies user preferences for handling ToDo items.\n",
    "   - It triggers the `update_instructions` node, which updates the chatbot's memory for **instructions** based on the user's message.\n",
    "\n",
    "4. **Stream Results**\n",
    "   - The graph processes the input in steps and streams intermediate results using `stream_mode=\"values\"`.\n",
    "   - The last message is displayed using `pretty_print()`, providing a readable summary of what the chatbot did.\n",
    "\n",
    "\n",
    "#### How does it work?\n",
    "\n",
    "1. **Analyze the Input**:\n",
    "   - The chatbot recognizes that the input contains new instructions for managing ToDo tasks, not personal information or specific tasks.\n",
    "\n",
    "2. **Decide to Update Instructions**:\n",
    "   - The system routes the input to the `update_instructions` node.\n",
    "   - This node updates the **instructions memory** for the user (`Julio`) with the new preference about urgency.\n",
    "\n",
    "3. **Save and Respond**:\n",
    "   - The updated instructions are stored in memory, replacing or adding to previous instructions.\n",
    "   - The chatbot does not explicitly tell the user about instruction updates (as per its design), but it applies the new instructions in future interactions.\n",
    "\n",
    "\n",
    "While there may not be a direct response to the user in this case, the chatbot will now use this updated instruction when managing tasks. For example, if a user later says, `\"Add 'Prepare a presentation' to my ToDo list,\"` the chatbot will automatically mark the task as **not urgent** unless the user specifies otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b49764-8d0b-4038-988d-bf809e836bbe",
   "metadata": {},
   "source": [
    "## Let's see the instruction memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6c4ead5-082e-4028-b477-fabc25ffb563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': '<current_instructions>\\nWhen creating or updating ToDo items, include if they are urgent or non-urgent. If the user does not specify, assume the task is not urgent.\\n</current_instructions>'}\n"
     ]
    }
   ],
   "source": [
    "# Check for updated instructions\n",
    "user_id = \"Julio\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"instructions\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1908ae89-b36f-4ad3-8956-e76cbd736faa",
   "metadata": {},
   "source": [
    "## Did you see? The instruction memory is now updated. Let's review what we just did.\n",
    "\n",
    "The previous code is used to **retrieve and view the updated instructions** stored in the chatbot's memory for a specific user (`Julio`). Here's a simple explanation:\n",
    "\n",
    "#### What does the code do?\n",
    "\n",
    "1. **Specify the User**:\n",
    "   - The variable `user_id` is set to `\"Julio\"`, indicating that we want to retrieve instructions associated with Julio.\n",
    "\n",
    "2. **Search for Instructions**:\n",
    "   - The `across_thread_memory.search` function is used to look for memory items stored under the **\"instructions\"** namespace for the user with ID `\"Julio\"`.\n",
    "   - `(\"instructions\", user_id)` acts like a label to identify the specific set of instructions in the memory.\n",
    "\n",
    "3. **Print the Results**:\n",
    "   - For each memory item found, the code prints its `value`, which contains the actual instructions stored in memory.\n",
    "\n",
    "\n",
    "#### How does it work?\n",
    "\n",
    "- **Memory Lookup**: The `across_thread_memory` object stores long-term memory (persistent data across sessions or threads).\n",
    "- **Namespace Filtering**: The search specifically targets memory entries under the `\"instructions\"` category for Julio.\n",
    "- **Accessing Stored Data**: The `memory.value` attribute retrieves the content (the instructions) stored in the memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576b46f1-ea57-4322-a6d0-39e3fef8db36",
   "metadata": {},
   "source": [
    "## OK. Let's enter a second task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f300e149-5559-4556-bfc4-bde938c23f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Schedule monthly meeting with the USA Sales Team.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_dQk57bOe9oHQlhcULLNHuFwh)\n",
      " Call ID: call_dQk57bOe9oHQlhcULLNHuFwh\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Updated ToDo: {'task': 'Schedule monthly meeting with the USA Sales Team.', 'time_to_complete': 60, 'solutions': ['Use a recurring calendar event to schedule the meeting.', 'Ensure all team members are available at the chosen time.', 'Prepare an agenda in advance.'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added \"Schedule monthly meeting with the USA Sales Team\" to your ToDo list. Let me know if there's anything else you need help with!\n"
     ]
    }
   ],
   "source": [
    "# User input for a ToDo\n",
    "input_messages = [HumanMessage(content=\"Schedule monthly meeting with the USA Sales Team.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4cb02-8915-44a2-b449-ec8990f4cdb5",
   "metadata": {},
   "source": [
    "## How can you see a list of all the ToDo tasks? Take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae394955-7707-4244-adfe-2afba10a9763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'Schedule interviews with candidates for California Sales Manager.', 'time_to_complete': 120, 'deadline': None, 'solutions': ['Use scheduling software like Calendly or Doodle to coordinate times.', 'Contact candidates via email or phone to confirm availability.', 'Coordinate with the hiring team to ensure their availability.'], 'status': 'not started'}\n",
      "{'task': 'Schedule monthly meeting with the USA Sales Team.', 'time_to_complete': 60, 'deadline': None, 'solutions': ['Use a recurring calendar event to schedule the meeting.', 'Ensure all team members are available at the chosen time.', 'Prepare an agenda in advance.'], 'status': 'not started'}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"Julio\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28ab6e0-b9f3-4e69-8b5e-a71f28af4c21",
   "metadata": {},
   "source": [
    "## Let's explain in simple terms what we just did\n",
    "\n",
    "The previous two blocks of code demonstrate how the chatbot processes a user's input to add a new task to their **ToDo list**, updates the memory, and retrieves the stored tasks to verify the update. Here's a simple explanation:\n",
    "\n",
    "\n",
    "#### What does the code do?\n",
    "\n",
    "1. **User Input for a Task**:\n",
    "   - The user provides a task message: \n",
    "     ```\n",
    "     \"Schedule monthly meeting with the USA Sales Team.\"\n",
    "     ```\n",
    "   - This input indicates a new task that the chatbot should add to the user's **ToDo list**.\n",
    "\n",
    "2. **Run the Graph**:\n",
    "   - The `graph.stream` function processes the message using the chatbot's workflow.\n",
    "   - The workflow decides that this input is related to a **ToDo item** and triggers the appropriate node (e.g., `update_todos`).\n",
    "   - The system adds the task to the **ToDo list** memory for the user (`Julio`).\n",
    "   - The chatbot's response (e.g., confirmation or feedback) is streamed and printed using `pretty_print()`.\n",
    "\n",
    "3. **Namespace for Memory**:\n",
    "   - The variable `user_id` is set to `\"Julio\"`, targeting the specific user's memory.\n",
    "\n",
    "4. **Retrieve ToDo List**:\n",
    "   - The `across_thread_memory.search((\"todo\", user_id))` searches for all tasks stored in the memory under the **\"todo\"** namespace for Julio.\n",
    "   - For each task found, the task details (`memory.value`) are printed.\n",
    "\n",
    "\n",
    "#### How does it work?\n",
    "\n",
    "1. **Analyze the Input**:\n",
    "   - The chatbot identifies the message as a task and decides to add it to the ToDo list.\n",
    "\n",
    "2. **Store the Task**:\n",
    "   - The task is added to the **ToDo list memory** for Julio in long-term storage (`across_thread_memory`).\n",
    "\n",
    "3. **Verify the Update**:\n",
    "   - The search function retrieves all tasks stored under Julio's ToDo list.\n",
    "   - Printing `memory.value` ensures the task was saved correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765320c2-d943-46b2-8448-e22c9b888926",
   "metadata": {},
   "source": [
    "## And what if you want to update an existing todo task? See how you can do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fae0b3b-c783-4d2a-9dd0-d94869bfc12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "For the task to schedule monthly meeting with the USA Sales Team, I need to get that done by end of month.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_KPTq6T7WoGJtzVzwT1yU96GH)\n",
      " Call ID: call_KPTq6T7WoGJtzVzwT1yU96GH\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "No updates for ToDo.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've noted that the task to schedule the monthly meeting with the USA Sales Team needs to be completed by the end of the month. If there's anything else you'd like to adjust or add, just let me know!\n"
     ]
    }
   ],
   "source": [
    "# User input to update an existing ToDo\n",
    "input_messages = [HumanMessage(content=\"For the task to schedule monthly meeting with the USA Sales Team, I need to get that done by end of month.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc405ab7-c97d-4987-8660-15354dc3945e",
   "metadata": {},
   "source": [
    "## That sure worked. Let's explain how we did it.\n",
    "\n",
    "The previous code demonstrates how the chatbot processes a user's input to **update an existing task** in their **ToDo list**, ensuring the task details are modified and stored correctly. Here's a simple explanation:\n",
    "\n",
    "\n",
    "#### What does the code do?\n",
    "\n",
    "1. **User Input to Update a Task**:\n",
    "   - The user provides an update for an existing task:\n",
    "     ```\n",
    "     \"For the task to schedule monthly meeting with the USA Sales Team, I need to get that done by end of month.\"\n",
    "     ```\n",
    "   - This input specifies additional information about the task (a deadline: \"end of month\").\n",
    "\n",
    "2. **Run the Graph**:\n",
    "   - The `graph.stream` function processes the input using the chatbot's workflow.\n",
    "   - The workflow identifies that this input is related to **updating an existing ToDo item**.\n",
    "   - The chatbot modifies the corresponding task in the user's **ToDo list memory** to include the new deadline.\n",
    "\n",
    "3. **Stream Results**:\n",
    "   - The chatbot's response, confirming the task update or providing feedback, is streamed step-by-step.\n",
    "   - The last processed message is displayed in a user-friendly format using `pretty_print()`.\n",
    "\n",
    "\n",
    "#### How does it work?\n",
    "\n",
    "1. **Task Identification**:\n",
    "   - The chatbot searches for the existing task (\"schedule monthly meeting with the USA Sales Team\") in the user's **ToDo list memory**.\n",
    "   - It identifies the task that matches the user's description.\n",
    "\n",
    "2. **Task Update**:\n",
    "   - The chatbot updates the task by adding the specified deadline (\"end of month\") to its details.\n",
    "   - It modifies the corresponding memory entry in long-term storage.\n",
    "\n",
    "3. **User Feedback**:\n",
    "   - The chatbot may confirm the update by generating a response like:\n",
    "     ```\n",
    "     \"I've updated the task 'Schedule monthly meeting with the USA Sales Team' to include a deadline of 'end of month.'\"\n",
    "     ```\n",
    "\n",
    "\n",
    "#### Why is it important?\n",
    "\n",
    "1. **Task Updates**: Demonstrates how the chatbot can modify existing tasks based on user input, keeping the ToDo list up-to-date.\n",
    "2. **Dynamic Memory**: Shows that the memory system isn't static but can adapt and evolve based on user needs.\n",
    "3. **User Engagement**: The chatbot provides clear feedback, ensuring the user knows their updates were applied.\n",
    "\n",
    "\n",
    "#### Example Output\n",
    "\n",
    "**Chatbot Response**:\n",
    "While running the graph, the chatbot might respond:\n",
    "```\n",
    "\"I've updated the task 'Schedule monthly meeting with the USA Sales Team' to include a deadline of 'end of month.'\"\n",
    "```\n",
    "\n",
    "**Updated Memory**:\n",
    "The updated task in memory might look like:\n",
    "```json\n",
    "{\n",
    "  \"task\": \"Schedule monthly meeting with the USA Sales Team\",\n",
    "  \"status\": \"not started\",\n",
    "  \"deadline\": \"end of month\"\n",
    "}\n",
    "```\n",
    "\n",
    "This confirms the chatbot successfully updated the task with the new information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be8064a-6fa4-419b-9a72-6243fde05605",
   "metadata": {},
   "source": [
    "## Excellent. Finally, let's enter a third todo task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd103d90-beb1-4114-8abb-f5078624ed43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Prepare the content for the meetings with Gen AI Teams of USA, Europe, and India.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_sDuVimTbek29UJyzczWuO34A)\n",
      " Call ID: call_sDuVimTbek29UJyzczWuO34A\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Updated ToDo: {'task': 'Prepare the content for the meetings with Gen AI Teams of USA, Europe, and India.', 'time_to_complete': 180, 'solutions': ['Research recent developments in AI relevant to each region.', 'Draft an agenda tailored to the interests and needs of each team.', 'Include discussion points on collaboration opportunities across regions.'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added \"Prepare the content for the meetings with Gen AI Teams of USA, Europe, and India\" to your ToDo list. If there's anything else you need, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# User input for a ToDo\n",
    "input_messages = [HumanMessage(content=\"Prepare the content for the meetings with Gen AI Teams of USA, Europe, and India.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fccc1f-64c6-47c9-8abe-3a9b7f0dc0ce",
   "metadata": {},
   "source": [
    "## And, to end this exercise, let's review the current list of todo tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a6a4c86-b158-4109-a4bf-ac310804f85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'Schedule interviews with candidates for California Sales Manager.', 'time_to_complete': 120, 'deadline': None, 'solutions': ['Use scheduling software like Calendly or Doodle to coordinate times.', 'Contact candidates via email or phone to confirm availability.', 'Coordinate with the hiring team to ensure their availability.'], 'status': 'not started'}\n",
      "{'task': 'Schedule monthly meeting with the USA Sales Team.', 'time_to_complete': 60, 'deadline': '2025-01-31T23:59:59', 'solutions': ['Use a recurring calendar event to schedule the meeting.', 'Ensure all team members are available at the chosen time.', 'Prepare an agenda in advance.'], 'status': 'not started'}\n",
      "{'task': 'Prepare the content for the meetings with Gen AI Teams of USA, Europe, and India.', 'time_to_complete': 180, 'deadline': None, 'solutions': ['Research recent developments in AI relevant to each region.', 'Draft an agenda tailored to the interests and needs of each team.', 'Include discussion points on collaboration opportunities across regions.'], 'status': 'not started'}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"Julio\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719db1c-0d3f-4824-b610-66ef006e9213",
   "metadata": {},
   "source": [
    "## One more thing: let's see what happens when we complete a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "501e7187-759f-4526-a503-ea617a56058d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I have completed the task Schedule interviews with candidates for California Sales Manager..\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_jkwZal7smCG2KYh3kpHt6rIO)\n",
      " Call ID: call_jkwZal7smCG2KYh3kpHt6rIO\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "No updates for ToDo.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great job on completing the task to schedule interviews with candidates for the California Sales Manager position! If there's anything else you need help with, just let me know.\n"
     ]
    }
   ],
   "source": [
    "# User input to update an existing ToDo\n",
    "input_messages = [HumanMessage(content=\"I have completed the task Schedule interviews with candidates for California Sales Manager..\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e46868-81af-4f07-95f2-acd01c4ace2c",
   "metadata": {},
   "source": [
    "## Has the status of the completed task changed? Let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3096c5ca-1fed-441c-99e5-4f3dcf0df2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'Schedule interviews with candidates for California Sales Manager.', 'time_to_complete': 120, 'deadline': None, 'solutions': ['Use scheduling software like Calendly or Doodle to coordinate times.', 'Contact candidates via email or phone to confirm availability.', 'Coordinate with the hiring team to ensure their availability.'], 'status': 'done'}\n",
      "{'task': 'Schedule monthly meeting with the USA Sales Team.', 'time_to_complete': 60, 'deadline': '2025-01-31T23:59:59', 'solutions': ['Use a recurring calendar event to schedule the meeting.', 'Ensure all team members are available at the chosen time.', 'Prepare an agenda in advance.'], 'status': 'not started'}\n",
      "{'task': 'Prepare the content for the meetings with Gen AI Teams of USA, Europe, and India.', 'time_to_complete': 180, 'deadline': None, 'solutions': ['Research recent developments in AI relevant to each region.', 'Draft an agenda tailored to the interests and needs of each team.', 'Include discussion points on collaboration opportunities across regions.'], 'status': 'not started'}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"Julio\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55370a6-3be6-4954-a064-85d216418187",
   "metadata": {},
   "source": [
    "* As you can see, now **the status of the first task appears as \"done\"**. From this point forward, we could continue improving our Agent in the directions we wish to pursue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc24f4f-d23c-4202-992d-91b0623136ae",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 028-agent-with-LT-memory.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 028-agent-with-LT-memory.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af248e-6069-44b3-a2cd-a20aa3259874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
